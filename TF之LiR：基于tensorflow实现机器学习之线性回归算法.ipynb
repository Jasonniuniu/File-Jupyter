{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TF之LiR：基于tensorflow实现机器学习之线性回归算法\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X： [  3.3     4.4     5.5     6.71    6.93    4.168   9.779   6.182   7.59\n",
      "   2.167   7.042  10.791   5.313   7.997   5.654   9.27    3.1  ]\n",
      "train_Y： [ 1.7    2.76   2.09   3.19   1.694  1.573  3.366  2.596  2.53   1.221\n",
      "  2.827  3.465  1.65   2.904  2.42   2.94   1.3  ]\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077094696 W= 0.244039 b= 0.842198\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077060968 W= 0.246223 b= 0.842695\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077051446 W= 0.245877 b= 0.842632\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077279359 W= 0.24863 b= 0.843042\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077050880 W= 0.245075 b= 0.842529\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077075340 W= 0.244362 b= 0.842358\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077049628 W= 0.245133 b= 0.842437\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077053465 W= 0.245999 b= 0.842577\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077048808 W= 0.245197 b= 0.842471\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077051997 W= 0.245002 b= 0.842381\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077055000 W= 0.246076 b= 0.842534\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077050321 W= 0.245867 b= 0.842514\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077078447 W= 0.244308 b= 0.842221\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077056780 W= 0.244816 b= 0.842285\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077046514 W= 0.24546 b= 0.842398\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077069253 W= 0.24449 b= 0.842294\n",
      "迭代次数Epoch: 0050 下降值cost= 0.077101581 W= 0.243943 b= 0.842117\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077082142 W= 0.244378 b= 0.839778\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077048205 W= 0.246565 b= 0.840275\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077038705 W= 0.24622 b= 0.840212\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077266969 W= 0.248974 b= 0.840623\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077038094 W= 0.245419 b= 0.84011\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077062339 W= 0.244708 b= 0.839939\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077036917 W= 0.245474 b= 0.840017\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077040769 W= 0.246341 b= 0.840158\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077036083 W= 0.245538 b= 0.840052\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077039234 W= 0.245345 b= 0.839963\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077042334 W= 0.246419 b= 0.840115\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077037513 W= 0.246202 b= 0.840095\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077065974 W= 0.244645 b= 0.839802\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077044278 W= 0.245152 b= 0.839866\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077033818 W= 0.245797 b= 0.83998\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077056885 W= 0.244824 b= 0.839875\n",
      "迭代次数Epoch: 0100 下降值cost= 0.077089250 W= 0.244279 b= 0.839699\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077071004 W= 0.244697 b= 0.8375\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077036865 W= 0.246886 b= 0.837998\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077027403 W= 0.246543 b= 0.837935\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077255920 W= 0.249297 b= 0.838346\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077026688 W= 0.245743 b= 0.837833\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077050820 W= 0.245034 b= 0.837663\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077025600 W= 0.245794 b= 0.83774\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077029452 W= 0.246663 b= 0.837881\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077024773 W= 0.245859 b= 0.837775\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077027917 W= 0.245668 b= 0.837687\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077031098 W= 0.246742 b= 0.837839\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077026106 W= 0.246517 b= 0.837819\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077054903 W= 0.244962 b= 0.837526\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077033140 W= 0.245468 b= 0.837589\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077022552 W= 0.246115 b= 0.837704\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077045947 W= 0.245138 b= 0.837598\n",
      "迭代次数Epoch: 0150 下降值cost= 0.077078328 W= 0.244595 b= 0.837423\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077061094 W= 0.244997 b= 0.83536\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077026807 W= 0.247188 b= 0.835858\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077017382 W= 0.246847 b= 0.835796\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077246182 W= 0.249601 b= 0.836207\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077016585 W= 0.246047 b= 0.835694\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077040516 W= 0.24534 b= 0.835524\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077015579 W= 0.246096 b= 0.835602\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077019423 W= 0.246965 b= 0.835742\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077014714 W= 0.24616 b= 0.835636\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077017829 W= 0.245972 b= 0.835549\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077021107 W= 0.247046 b= 0.835702\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077015996 W= 0.246814 b= 0.83568\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077045076 W= 0.24526 b= 0.835388\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077023298 W= 0.245765 b= 0.835451\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077012546 W= 0.246413 b= 0.835566\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077036209 W= 0.245433 b= 0.83546\n",
      "迭代次数Epoch: 0200 下降值cost= 0.077068649 W= 0.244893 b= 0.835285\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077052318 W= 0.245279 b= 0.833346\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077017851 W= 0.247472 b= 0.833845\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077008471 W= 0.247133 b= 0.833783\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077237502 W= 0.249887 b= 0.834194\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077007592 W= 0.246333 b= 0.833681\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077031374 W= 0.245628 b= 0.833512\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077006653 W= 0.246379 b= 0.833588\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077010520 W= 0.247249 b= 0.833729\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077005774 W= 0.246444 b= 0.833623\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077008866 W= 0.246257 b= 0.833537\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077012248 W= 0.247331 b= 0.833689\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077006988 W= 0.247092 b= 0.833667\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077036373 W= 0.245541 b= 0.833375\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077014506 W= 0.246044 b= 0.833438\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077003658 W= 0.246694 b= 0.833553\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077027589 W= 0.24571 b= 0.833447\n",
      "迭代次数Epoch: 0250 下降值cost= 0.077060029 W= 0.245172 b= 0.833273\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077044509 W= 0.245544 b= 0.831451\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077009894 W= 0.247739 b= 0.83195\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077000529 W= 0.247401 b= 0.831889\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077229805 W= 0.250156 b= 0.832299\n",
      "迭代次数Epoch: 0300 下降值cost= 0.076999590 W= 0.246602 b= 0.831787\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077023230 W= 0.2459 b= 0.831618\n",
      "迭代次数Epoch: 0300 下降值cost= 0.076998696 W= 0.246646 b= 0.831694\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077002585 W= 0.247517 b= 0.831835\n",
      "迭代次数Epoch: 0300 下降值cost= 0.076997831 W= 0.246711 b= 0.831729\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077000916 W= 0.246526 b= 0.831644\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077004366 W= 0.2476 b= 0.831796\n",
      "迭代次数Epoch: 0300 下降值cost= 0.076998957 W= 0.247355 b= 0.831773\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077028617 W= 0.245805 b= 0.831482\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077006750 W= 0.246307 b= 0.831544\n",
      "迭代次数Epoch: 0300 下降值cost= 0.076995723 W= 0.246958 b= 0.83166\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077019930 W= 0.245972 b= 0.831553\n",
      "迭代次数Epoch: 0300 下降值cost= 0.077052407 W= 0.245435 b= 0.83138\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077037573 W= 0.245794 b= 0.829671\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077002823 W= 0.247991 b= 0.83017\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076993465 W= 0.247654 b= 0.830109\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077222988 W= 0.250409 b= 0.830519\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076992467 W= 0.246855 b= 0.830007\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077015989 W= 0.246154 b= 0.829838\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076991670 W= 0.246896 b= 0.829914\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076995522 W= 0.247768 b= 0.830055\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076990783 W= 0.246962 b= 0.829949\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076993823 W= 0.246778 b= 0.829864\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076997355 W= 0.247852 b= 0.830017\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076991841 W= 0.247601 b= 0.829994\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077021755 W= 0.246053 b= 0.829702\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076999828 W= 0.246554 b= 0.829765\n",
      "迭代次数Epoch: 0350 下降值cost= 0.076988697 W= 0.247207 b= 0.82988\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077013157 W= 0.246217 b= 0.829773\n",
      "迭代次数Epoch: 0350 下降值cost= 0.077045649 W= 0.245683 b= 0.829601\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077031404 W= 0.246028 b= 0.827995\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076996498 W= 0.248227 b= 0.828495\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076987185 W= 0.247891 b= 0.828434\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077216901 W= 0.250647 b= 0.828845\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076986142 W= 0.247093 b= 0.828332\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077009521 W= 0.246394 b= 0.828164\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076985382 W= 0.247132 b= 0.82824\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076989241 W= 0.248005 b= 0.828381\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076984480 W= 0.247198 b= 0.828275\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076987498 W= 0.247016 b= 0.82819\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076991111 W= 0.24809 b= 0.828343\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076985493 W= 0.247833 b= 0.828319\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077015638 W= 0.246286 b= 0.828028\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076993681 W= 0.246787 b= 0.82809\n",
      "迭代次数Epoch: 0400 下降值cost= 0.076982431 W= 0.24744 b= 0.828206\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077007115 W= 0.246448 b= 0.828099\n",
      "迭代次数Epoch: 0400 下降值cost= 0.077039652 W= 0.245915 b= 0.827927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 0450 下降值cost= 0.077025928 W= 0.246249 b= 0.82642\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076990902 W= 0.248449 b= 0.82692\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076981597 W= 0.248115 b= 0.826859\n",
      "迭代次数Epoch: 0450 下降值cost= 0.077211536 W= 0.250871 b= 0.82727\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076980501 W= 0.247317 b= 0.826757\n",
      "迭代次数Epoch: 0450 下降值cost= 0.077003747 W= 0.246619 b= 0.826589\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076979771 W= 0.247354 b= 0.826664\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076983638 W= 0.248228 b= 0.826806\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076978870 W= 0.24742 b= 0.826699\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076981895 W= 0.247239 b= 0.826616\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076985553 W= 0.248313 b= 0.826768\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076979846 W= 0.248051 b= 0.826744\n",
      "迭代次数Epoch: 0450 下降值cost= 0.077010214 W= 0.246505 b= 0.826453\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076988220 W= 0.247005 b= 0.826516\n",
      "迭代次数Epoch: 0450 下降值cost= 0.076976851 W= 0.24766 b= 0.826631\n",
      "迭代次数Epoch: 0450 下降值cost= 0.077001765 W= 0.246665 b= 0.826524\n",
      "迭代次数Epoch: 0450 下降值cost= 0.077034302 W= 0.246134 b= 0.826353\n",
      "迭代次数Epoch: 0500 下降值cost= 0.077021055 W= 0.246457 b= 0.824937\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076985896 W= 0.248659 b= 0.825438\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076976620 W= 0.248325 b= 0.825377\n",
      "迭代次数Epoch: 0500 下降值cost= 0.077206738 W= 0.251082 b= 0.825788\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076975472 W= 0.247528 b= 0.825275\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076998606 W= 0.246832 b= 0.825108\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076974802 W= 0.247563 b= 0.825183\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076978676 W= 0.248437 b= 0.825324\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076973893 W= 0.247629 b= 0.825218\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076976888 W= 0.24745 b= 0.825135\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076980628 W= 0.248524 b= 0.825287\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076974802 W= 0.248256 b= 0.825262\n",
      "迭代次数Epoch: 0500 下降值cost= 0.077005371 W= 0.246712 b= 0.824972\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076983362 W= 0.247211 b= 0.825034\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076971903 W= 0.247867 b= 0.82515\n",
      "迭代次数Epoch: 0500 下降值cost= 0.076996997 W= 0.24687 b= 0.825043\n",
      "迭代次数Epoch: 0500 下降值cost= 0.077029556 W= 0.24634 b= 0.824872\n",
      "迭代次数Epoch: 0550 下降值cost= 0.077016711 W= 0.246652 b= 0.823543\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076981433 W= 0.248855 b= 0.824044\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076972187 W= 0.248523 b= 0.823983\n",
      "迭代次数Epoch: 0550 下降值cost= 0.077202477 W= 0.25128 b= 0.824394\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076970987 W= 0.247726 b= 0.823882\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076994009 W= 0.247031 b= 0.823715\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076970376 W= 0.247759 b= 0.823789\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076974228 W= 0.248634 b= 0.823931\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076969460 W= 0.247825 b= 0.823824\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076972447 W= 0.247647 b= 0.823742\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076976225 W= 0.248721 b= 0.823895\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076970302 W= 0.248449 b= 0.823869\n",
      "迭代次数Epoch: 0550 下降值cost= 0.077001065 W= 0.246906 b= 0.823579\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076979041 W= 0.247404 b= 0.823641\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076967470 W= 0.248061 b= 0.823757\n",
      "迭代次数Epoch: 0550 下降值cost= 0.076992780 W= 0.247062 b= 0.823649\n",
      "迭代次数Epoch: 0550 下降值cost= 0.077025354 W= 0.246534 b= 0.823479\n",
      "迭代次数Epoch: 0600 下降值cost= 0.077012844 W= 0.246836 b= 0.822233\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076977476 W= 0.24904 b= 0.822734\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076968253 W= 0.248709 b= 0.822673\n",
      "迭代次数Epoch: 0600 下降值cost= 0.077198692 W= 0.251466 b= 0.823084\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076967001 W= 0.247912 b= 0.822572\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076989926 W= 0.247218 b= 0.822405\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076966420 W= 0.247944 b= 0.822479\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076970279 W= 0.248819 b= 0.822621\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076965496 W= 0.24801 b= 0.822514\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076968461 W= 0.247833 b= 0.822433\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076972306 W= 0.248907 b= 0.822585\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076966308 W= 0.248631 b= 0.822559\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076997265 W= 0.247088 b= 0.822269\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076975197 W= 0.247586 b= 0.822331\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076963544 W= 0.248244 b= 0.822448\n",
      "迭代次数Epoch: 0600 下降值cost= 0.076989047 W= 0.247242 b= 0.82234\n",
      "迭代次数Epoch: 0600 下降值cost= 0.077021621 W= 0.246716 b= 0.82217\n",
      "迭代次数Epoch: 0650 下降值cost= 0.077009417 W= 0.247008 b= 0.821\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076973930 W= 0.249214 b= 0.821501\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076964721 W= 0.248883 b= 0.821441\n",
      "迭代次数Epoch: 0650 下降值cost= 0.077195339 W= 0.251641 b= 0.821852\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076963447 W= 0.248087 b= 0.821339\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076986283 W= 0.247395 b= 0.821173\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076962903 W= 0.248117 b= 0.821247\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076966755 W= 0.248993 b= 0.821389\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076961957 W= 0.248184 b= 0.821282\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076964922 W= 0.248008 b= 0.821201\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076968819 W= 0.249082 b= 0.821353\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076962739 W= 0.248801 b= 0.821327\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076993868 W= 0.24726 b= 0.821037\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076971784 W= 0.247757 b= 0.821099\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076960027 W= 0.248416 b= 0.821216\n",
      "迭代次数Epoch: 0650 下降值cost= 0.076985694 W= 0.247412 b= 0.821108\n",
      "迭代次数Epoch: 0650 下降值cost= 0.077018306 W= 0.246887 b= 0.820938\n",
      "迭代次数Epoch: 0700 下降值cost= 0.077006370 W= 0.247171 b= 0.819839\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076970771 W= 0.249378 b= 0.820341\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076961584 W= 0.249048 b= 0.820281\n",
      "迭代次数Epoch: 0700 下降值cost= 0.077192344 W= 0.251805 b= 0.820692\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076960258 W= 0.248252 b= 0.820179\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076983020 W= 0.247561 b= 0.820013\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076959752 W= 0.24828 b= 0.820087\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076963618 W= 0.249157 b= 0.820229\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076958835 W= 0.248347 b= 0.820122\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076961756 W= 0.248172 b= 0.820041\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076965697 W= 0.249247 b= 0.820194\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076959558 W= 0.248962 b= 0.820167\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076990843 W= 0.247422 b= 0.819877\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076968729 W= 0.247918 b= 0.819939\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076956913 W= 0.248578 b= 0.820056\n",
      "迭代次数Epoch: 0700 下降值cost= 0.076982744 W= 0.247572 b= 0.819948\n",
      "迭代次数Epoch: 0700 下降值cost= 0.077015340 W= 0.247048 b= 0.819779\n",
      "迭代次数Epoch: 0750 下降值cost= 0.077003635 W= 0.247324 b= 0.818748\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076967962 W= 0.249532 b= 0.819249\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076958783 W= 0.249203 b= 0.81919\n",
      "迭代次数Epoch: 0750 下降值cost= 0.077189684 W= 0.251961 b= 0.819601\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076957405 W= 0.248407 b= 0.819088\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076980092 W= 0.247717 b= 0.818922\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076956950 W= 0.248434 b= 0.818995\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076960817 W= 0.249311 b= 0.819137\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076956019 W= 0.248501 b= 0.819031\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076958932 W= 0.248327 b= 0.81895\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076962925 W= 0.249401 b= 0.819103\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076956697 W= 0.249113 b= 0.819076\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076988153 W= 0.247574 b= 0.818786\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076966025 W= 0.248069 b= 0.818848\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076954126 W= 0.24873 b= 0.818965\n",
      "迭代次数Epoch: 0750 下降值cost= 0.076980092 W= 0.247723 b= 0.818857\n",
      "迭代次数Epoch: 0750 下降值cost= 0.077012718 W= 0.2472 b= 0.818688\n",
      "迭代次数Epoch: 0800 下降值cost= 0.077001192 W= 0.247468 b= 0.81772\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076965444 W= 0.249677 b= 0.818222\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076956280 W= 0.249349 b= 0.818162\n",
      "迭代次数Epoch: 0800 下降值cost= 0.077187315 W= 0.252106 b= 0.818573\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076954857 W= 0.248553 b= 0.818061\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076977462 W= 0.247864 b= 0.817895\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076954454 W= 0.248579 b= 0.817968\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076958306 W= 0.249456 b= 0.81811\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076953508 W= 0.248646 b= 0.818004\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076956406 W= 0.248473 b= 0.817924\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076960444 W= 0.249547 b= 0.818076\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076954149 W= 0.249256 b= 0.818049\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076985747 W= 0.247717 b= 0.81776\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076963603 W= 0.248212 b= 0.817822\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076951616 W= 0.248873 b= 0.817938\n",
      "迭代次数Epoch: 0800 下降值cost= 0.076977752 W= 0.247864 b= 0.81783\n",
      "迭代次数Epoch: 0800 下降值cost= 0.077010371 W= 0.247342 b= 0.817661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 0850 下降值cost= 0.076999016 W= 0.247603 b= 0.816757\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076963209 W= 0.249813 b= 0.81726\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076954059 W= 0.249485 b= 0.8172\n",
      "迭代次数Epoch: 0850 下降值cost= 0.077185199 W= 0.252243 b= 0.817611\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076952621 W= 0.24869 b= 0.817098\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076975130 W= 0.248002 b= 0.816933\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076952219 W= 0.248714 b= 0.817006\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076956071 W= 0.249592 b= 0.817148\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076951250 W= 0.248782 b= 0.817041\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076954171 W= 0.248609 b= 0.816962\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076958239 W= 0.249684 b= 0.817114\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076951876 W= 0.249389 b= 0.817087\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076983631 W= 0.247851 b= 0.816798\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076961458 W= 0.248345 b= 0.816859\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076949403 W= 0.249007 b= 0.816977\n",
      "迭代次数Epoch: 0850 下降值cost= 0.076975651 W= 0.247997 b= 0.816868\n",
      "迭代次数Epoch: 0850 下降值cost= 0.077008300 W= 0.247476 b= 0.8167\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076997109 W= 0.24773 b= 0.81585\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076961197 W= 0.249941 b= 0.816353\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076952063 W= 0.249614 b= 0.816293\n",
      "迭代次数Epoch: 0900 下降值cost= 0.077183306 W= 0.252372 b= 0.816704\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076950572 W= 0.248819 b= 0.816192\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076973058 W= 0.248132 b= 0.816027\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076950222 W= 0.248842 b= 0.816099\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076954089 W= 0.24972 b= 0.816241\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076949283 W= 0.24891 b= 0.816135\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076952145 W= 0.248738 b= 0.816055\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076956280 W= 0.249812 b= 0.816208\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076949872 W= 0.249514 b= 0.81618\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076981723 W= 0.247977 b= 0.815891\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076959535 W= 0.248471 b= 0.815953\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076947428 W= 0.249134 b= 0.81607\n",
      "迭代次数Epoch: 0900 下降值cost= 0.076973818 W= 0.248122 b= 0.815961\n",
      "迭代次数Epoch: 0900 下降值cost= 0.077006452 W= 0.247602 b= 0.815793\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076995373 W= 0.247849 b= 0.814997\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076959394 W= 0.250061 b= 0.8155\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076950267 W= 0.249735 b= 0.815441\n",
      "迭代次数Epoch: 0950 下降值cost= 0.077181645 W= 0.252493 b= 0.815852\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076948784 W= 0.24894 b= 0.815339\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076971181 W= 0.248254 b= 0.815174\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076948434 W= 0.248962 b= 0.815247\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076952286 W= 0.249841 b= 0.815389\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076947488 W= 0.24903 b= 0.815282\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076950349 W= 0.248859 b= 0.815203\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076954514 W= 0.249933 b= 0.815356\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076948062 W= 0.249632 b= 0.815328\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076980017 W= 0.248096 b= 0.815039\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076957829 W= 0.24859 b= 0.8151\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076945640 W= 0.249253 b= 0.815218\n",
      "迭代次数Epoch: 0950 下降值cost= 0.076972164 W= 0.24824 b= 0.815108\n",
      "迭代次数Epoch: 0950 下降值cost= 0.077004798 W= 0.247721 b= 0.814941\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076993838 W= 0.247962 b= 0.814194\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076957785 W= 0.250174 b= 0.814697\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076948687 W= 0.249849 b= 0.814638\n",
      "迭代次数Epoch: 1000 下降值cost= 0.077180147 W= 0.252607 b= 0.815049\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076947153 W= 0.249054 b= 0.814536\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076969489 W= 0.248368 b= 0.814372\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076946847 W= 0.249075 b= 0.814444\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076950714 W= 0.249954 b= 0.814586\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076945864 W= 0.249143 b= 0.814479\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076948740 W= 0.248973 b= 0.814401\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076952934 W= 0.250047 b= 0.814553\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076946408 W= 0.249744 b= 0.814525\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076978505 W= 0.248208 b= 0.814236\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076956302 W= 0.248701 b= 0.814298\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076944061 W= 0.249365 b= 0.814415\n",
      "迭代次数Epoch: 1000 下降值cost= 0.076970696 W= 0.24835 b= 0.814306\n",
      "迭代次数Epoch: 1000 下降值cost= 0.077003345 W= 0.247832 b= 0.814139\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076992445 W= 0.248068 b= 0.813437\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076956339 W= 0.250281 b= 0.81394\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076947242 W= 0.249956 b= 0.813881\n",
      "迭代次数Epoch: 1050 下降值cost= 0.077178828 W= 0.252715 b= 0.814292\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076945700 W= 0.249162 b= 0.81378\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076967992 W= 0.248477 b= 0.813616\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076945402 W= 0.249182 b= 0.813688\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076949276 W= 0.250061 b= 0.81383\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076944433 W= 0.24925 b= 0.813723\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076947302 W= 0.24908 b= 0.813645\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076951526 W= 0.250154 b= 0.813797\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076944940 W= 0.249848 b= 0.813769\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076977156 W= 0.248313 b= 0.81348\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076954924 W= 0.248806 b= 0.813542\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076942623 W= 0.24947 b= 0.813659\n",
      "迭代次数Epoch: 1050 下降值cost= 0.076969385 W= 0.248455 b= 0.81355\n",
      "迭代次数Epoch: 1050 下降值cost= 0.077002034 W= 0.247937 b= 0.813383\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076991230 W= 0.248167 b= 0.812728\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076955065 W= 0.250381 b= 0.813231\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076945961 W= 0.250057 b= 0.813172\n",
      "迭代次数Epoch: 1100 下降值cost= 0.077177644 W= 0.252815 b= 0.813583\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076944403 W= 0.249262 b= 0.813071\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076966628 W= 0.248578 b= 0.812906\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076944135 W= 0.249282 b= 0.812978\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076947995 W= 0.250161 b= 0.813121\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076943167 W= 0.24935 b= 0.813014\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076946005 W= 0.249181 b= 0.812936\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076950252 W= 0.250255 b= 0.813088\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076943643 W= 0.249947 b= 0.81306\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076975942 W= 0.248412 b= 0.812771\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076953709 W= 0.248904 b= 0.812832\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076941371 W= 0.249569 b= 0.81295\n",
      "迭代次数Epoch: 1100 下降值cost= 0.076968201 W= 0.248552 b= 0.81284\n",
      "迭代次数Epoch: 1100 下降值cost= 0.077000879 W= 0.248036 b= 0.812674\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076990128 W= 0.248261 b= 0.812058\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076953903 W= 0.250476 b= 0.812562\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076944835 W= 0.250152 b= 0.812503\n",
      "迭代次数Epoch: 1150 下降值cost= 0.077176578 W= 0.25291 b= 0.812914\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076943219 W= 0.249357 b= 0.812401\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076965407 W= 0.248674 b= 0.812237\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076942980 W= 0.249376 b= 0.812309\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076946862 W= 0.250256 b= 0.812451\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076942004 W= 0.249444 b= 0.812344\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076944858 W= 0.249276 b= 0.812267\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076949142 W= 0.25035 b= 0.812419\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076942489 W= 0.250039 b= 0.812391\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076974884 W= 0.248505 b= 0.812102\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076952621 W= 0.248997 b= 0.812163\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076940224 W= 0.249663 b= 0.812281\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076967165 W= 0.248645 b= 0.812171\n",
      "迭代次数Epoch: 1150 下降值cost= 0.076999843 W= 0.248129 b= 0.812005\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076989144 W= 0.248349 b= 0.811428\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076952875 W= 0.250564 b= 0.811932\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076943792 W= 0.250241 b= 0.811873\n",
      "迭代次数Epoch: 1200 下降值cost= 0.077175632 W= 0.253 b= 0.812284\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076942176 W= 0.249447 b= 0.811772\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076964311 W= 0.248764 b= 0.811608\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076941967 W= 0.249464 b= 0.811679\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076945826 W= 0.250345 b= 0.811822\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076940969 W= 0.249533 b= 0.811715\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076943807 W= 0.249365 b= 0.811637\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076948106 W= 0.250439 b= 0.81179\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076941431 W= 0.250126 b= 0.811761\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076973900 W= 0.248593 b= 0.811472\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076951638 W= 0.249085 b= 0.811534\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076939188 W= 0.24975 b= 0.811652\n",
      "迭代次数Epoch: 1200 下降值cost= 0.076966226 W= 0.248732 b= 0.811542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 1200 下降值cost= 0.076998904 W= 0.248216 b= 0.811375\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076988280 W= 0.248432 b= 0.810839\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076951936 W= 0.250648 b= 0.811343\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076942876 W= 0.250324 b= 0.811284\n",
      "迭代次数Epoch: 1250 下降值cost= 0.077174775 W= 0.253084 b= 0.811695\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076941222 W= 0.249531 b= 0.811182\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076963328 W= 0.248849 b= 0.811019\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076941036 W= 0.249547 b= 0.81109\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076944910 W= 0.250428 b= 0.811233\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076940052 W= 0.249616 b= 0.811126\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076942891 W= 0.249449 b= 0.811048\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076947197 W= 0.250523 b= 0.811201\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076940484 W= 0.250208 b= 0.811172\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076973028 W= 0.248675 b= 0.810883\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076950766 W= 0.249166 b= 0.810945\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076938279 W= 0.249833 b= 0.811063\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076965392 W= 0.248813 b= 0.810952\n",
      "迭代次数Epoch: 1250 下降值cost= 0.076998070 W= 0.248298 b= 0.810786\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076987475 W= 0.24851 b= 0.810285\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076951101 W= 0.250726 b= 0.810789\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076942056 W= 0.250403 b= 0.81073\n",
      "迭代次数Epoch: 1300 下降值cost= 0.077174023 W= 0.253162 b= 0.811141\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076940402 W= 0.249609 b= 0.810628\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076962441 W= 0.248928 b= 0.810465\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076940209 W= 0.249625 b= 0.810536\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076944083 W= 0.250506 b= 0.810679\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076939218 W= 0.249694 b= 0.810572\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076942042 W= 0.249527 b= 0.810495\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076946385 W= 0.250601 b= 0.810647\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076939628 W= 0.250285 b= 0.810618\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076972269 W= 0.248752 b= 0.81033\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076949991 W= 0.249243 b= 0.810391\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076937459 W= 0.24991 b= 0.810509\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076964661 W= 0.248889 b= 0.810399\n",
      "迭代次数Epoch: 1300 下降值cost= 0.076997340 W= 0.248375 b= 0.810233\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076986782 W= 0.248583 b= 0.809762\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076950349 W= 0.2508 b= 0.810266\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076941311 W= 0.250477 b= 0.810207\n",
      "迭代次数Epoch: 1350 下降值cost= 0.077173345 W= 0.253236 b= 0.810619\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076939642 W= 0.249684 b= 0.810106\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076961637 W= 0.249003 b= 0.809942\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076939486 W= 0.249699 b= 0.810014\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076943345 W= 0.25058 b= 0.810156\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076938480 W= 0.249767 b= 0.810049\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076941289 W= 0.249601 b= 0.809973\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076945670 W= 0.250676 b= 0.810125\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076938875 W= 0.250357 b= 0.810096\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076971591 W= 0.248825 b= 0.809807\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076949298 W= 0.249316 b= 0.809869\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076936737 W= 0.249983 b= 0.809987\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076964006 W= 0.248961 b= 0.809876\n",
      "迭代次数Epoch: 1350 下降值cost= 0.076996684 W= 0.248448 b= 0.809711\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076986134 W= 0.248652 b= 0.80927\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076949693 W= 0.250869 b= 0.809774\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076940633 W= 0.250547 b= 0.809715\n",
      "迭代次数Epoch: 1400 下降值cost= 0.077172749 W= 0.253306 b= 0.810126\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076938942 W= 0.249754 b= 0.809614\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076960914 W= 0.249073 b= 0.80945\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076938808 W= 0.249768 b= 0.809521\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076942660 W= 0.25065 b= 0.809664\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076937810 W= 0.249837 b= 0.809557\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076940618 W= 0.249671 b= 0.80948\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076945014 W= 0.250745 b= 0.809633\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076938197 W= 0.250425 b= 0.809603\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076970957 W= 0.248894 b= 0.809315\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076948673 W= 0.249384 b= 0.809376\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076936066 W= 0.250051 b= 0.809494\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076963417 W= 0.249029 b= 0.809384\n",
      "迭代次数Epoch: 1400 下降值cost= 0.076996095 W= 0.248516 b= 0.809219\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076985583 W= 0.248716 b= 0.80881\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076949060 W= 0.250934 b= 0.809314\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076940045 W= 0.250612 b= 0.809256\n",
      "迭代次数Epoch: 1450 下降值cost= 0.077172220 W= 0.253372 b= 0.809667\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076938339 W= 0.249819 b= 0.809154\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076960273 W= 0.249139 b= 0.808991\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076938204 W= 0.249833 b= 0.809062\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076942071 W= 0.250715 b= 0.809205\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076937199 W= 0.249902 b= 0.809098\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076940000 W= 0.249736 b= 0.809022\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076944418 W= 0.250811 b= 0.809174\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076937571 W= 0.250489 b= 0.809144\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076970413 W= 0.248958 b= 0.808856\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076948091 W= 0.249448 b= 0.808917\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076935470 W= 0.250115 b= 0.809035\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076962888 W= 0.249092 b= 0.808925\n",
      "迭代次数Epoch: 1450 下降值cost= 0.076995559 W= 0.24858 b= 0.80876\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076985061 W= 0.248777 b= 0.808374\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076948524 W= 0.250995 b= 0.808878\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076939493 W= 0.250674 b= 0.80882\n",
      "迭代次数Epoch: 1500 下降值cost= 0.077171735 W= 0.253434 b= 0.809231\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076937765 W= 0.249881 b= 0.808719\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076959684 W= 0.249201 b= 0.808555\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076937653 W= 0.249894 b= 0.808626\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076941520 W= 0.250776 b= 0.808769\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076936655 W= 0.249963 b= 0.808662\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076939464 W= 0.249798 b= 0.808586\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076943882 W= 0.250872 b= 0.808738\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076937027 W= 0.250549 b= 0.808708\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076969922 W= 0.249018 b= 0.80842\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076947600 W= 0.249508 b= 0.808481\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076934926 W= 0.250176 b= 0.8086\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076962411 W= 0.249152 b= 0.808489\n",
      "迭代次数Epoch: 1500 下降值cost= 0.076995112 W= 0.24864 b= 0.808324\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076984592 W= 0.248835 b= 0.807965\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076948054 W= 0.251053 b= 0.808469\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076939024 W= 0.250732 b= 0.808411\n",
      "迭代次数Epoch: 1550 下降值cost= 0.077171288 W= 0.253492 b= 0.808822\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076937288 W= 0.249939 b= 0.808309\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076959148 W= 0.24926 b= 0.808146\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076937161 W= 0.249952 b= 0.808217\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076941051 W= 0.250834 b= 0.80836\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076936156 W= 0.250021 b= 0.808253\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076938957 W= 0.249856 b= 0.808177\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076943420 W= 0.25093 b= 0.808329\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076936521 W= 0.250606 b= 0.808299\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076969467 W= 0.249075 b= 0.808011\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076947138 W= 0.249565 b= 0.808072\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076934442 W= 0.250233 b= 0.808191\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076961994 W= 0.249209 b= 0.80808\n",
      "迭代次数Epoch: 1550 下降值cost= 0.076994687 W= 0.248697 b= 0.807915\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076984189 W= 0.248889 b= 0.807579\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076947585 W= 0.251108 b= 0.808084\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076938577 W= 0.250787 b= 0.808025\n",
      "迭代次数Epoch: 1600 下降值cost= 0.077170879 W= 0.253546 b= 0.808437\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076936841 W= 0.249994 b= 0.807924\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076958671 W= 0.249315 b= 0.807761\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076936737 W= 0.250006 b= 0.807832\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076940596 W= 0.250889 b= 0.807974\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076935723 W= 0.250075 b= 0.807867\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076938517 W= 0.249911 b= 0.807791\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076942965 W= 0.250985 b= 0.807944\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076936074 W= 0.250659 b= 0.807914\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076969072 W= 0.249129 b= 0.807626\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076946735 W= 0.249619 b= 0.807687\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076934002 W= 0.250287 b= 0.807805\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076961599 W= 0.249262 b= 0.807695\n",
      "迭代次数Epoch: 1600 下降值cost= 0.076994292 W= 0.248751 b= 0.80753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 1650 下降值cost= 0.076983832 W= 0.248939 b= 0.807217\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076947197 W= 0.251159 b= 0.807722\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076938190 W= 0.250838 b= 0.807663\n",
      "迭代次数Epoch: 1650 下降值cost= 0.077170551 W= 0.253598 b= 0.808075\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076936416 W= 0.250045 b= 0.807562\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076958239 W= 0.249367 b= 0.807399\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076936334 W= 0.250057 b= 0.80747\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076940201 W= 0.25094 b= 0.807613\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076935306 W= 0.250126 b= 0.807505\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076938093 W= 0.249962 b= 0.80743\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076942593 W= 0.251036 b= 0.807582\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076935634 W= 0.250709 b= 0.807552\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076968722 W= 0.249179 b= 0.807264\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076946363 W= 0.249669 b= 0.807325\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076933615 W= 0.250338 b= 0.807444\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076961271 W= 0.249312 b= 0.807333\n",
      "迭代次数Epoch: 1650 下降值cost= 0.076993972 W= 0.248801 b= 0.807168\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076983489 W= 0.248987 b= 0.806877\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076946802 W= 0.251207 b= 0.807382\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076937810 W= 0.250886 b= 0.807323\n",
      "迭代次数Epoch: 1700 下降值cost= 0.077170208 W= 0.253646 b= 0.807735\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076936051 W= 0.250094 b= 0.807222\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076957844 W= 0.249415 b= 0.807059\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076935992 W= 0.250105 b= 0.80713\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076939858 W= 0.250988 b= 0.807273\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076934963 W= 0.250174 b= 0.807165\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076937743 W= 0.25001 b= 0.80709\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076942220 W= 0.251085 b= 0.807242\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076935269 W= 0.250757 b= 0.807212\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076968387 W= 0.249227 b= 0.806924\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076946050 W= 0.249716 b= 0.806985\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076933242 W= 0.250385 b= 0.807104\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076960959 W= 0.249359 b= 0.806993\n",
      "迭代次数Epoch: 1700 下降值cost= 0.076993667 W= 0.248848 b= 0.806828\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076983191 W= 0.249032 b= 0.806556\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076946482 W= 0.251252 b= 0.80706\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076937497 W= 0.250932 b= 0.807002\n",
      "迭代次数Epoch: 1750 下降值cost= 0.077169955 W= 0.253692 b= 0.807413\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076935709 W= 0.250139 b= 0.806901\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076957479 W= 0.249461 b= 0.806738\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076935656 W= 0.25015 b= 0.806808\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076939523 W= 0.251033 b= 0.806951\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076934636 W= 0.250219 b= 0.806844\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076937407 W= 0.250056 b= 0.806769\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076941922 W= 0.25113 b= 0.806921\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076934926 W= 0.250801 b= 0.806891\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076968096 W= 0.249272 b= 0.806603\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076945737 W= 0.249761 b= 0.806664\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076932929 W= 0.25043 b= 0.806782\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076960675 W= 0.249403 b= 0.806672\n",
      "迭代次数Epoch: 1750 下降值cost= 0.076993383 W= 0.248893 b= 0.806507\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076982923 W= 0.249074 b= 0.806256\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076946199 W= 0.251294 b= 0.806761\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076937206 W= 0.250974 b= 0.806702\n",
      "迭代次数Epoch: 1800 下降值cost= 0.077169687 W= 0.253734 b= 0.807114\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076935425 W= 0.250182 b= 0.806601\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076957159 W= 0.249504 b= 0.806439\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076935351 W= 0.250193 b= 0.806509\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076939210 W= 0.251076 b= 0.806652\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076934338 W= 0.250262 b= 0.806545\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076937109 W= 0.250099 b= 0.806469\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076941624 W= 0.251173 b= 0.806622\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076934636 W= 0.250843 b= 0.806591\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076967828 W= 0.249313 b= 0.806303\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076945469 W= 0.249802 b= 0.806365\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076932646 W= 0.250472 b= 0.806483\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076960437 W= 0.249444 b= 0.806372\n",
      "迭代次数Epoch: 1800 下降值cost= 0.076993152 W= 0.248935 b= 0.806208\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076982670 W= 0.249114 b= 0.805973\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076945916 W= 0.251334 b= 0.806478\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076936938 W= 0.251015 b= 0.80642\n",
      "迭代次数Epoch: 1850 下降值cost= 0.077169478 W= 0.253775 b= 0.806831\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076935142 W= 0.250222 b= 0.806318\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076956853 W= 0.249545 b= 0.806156\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076935105 W= 0.250232 b= 0.806226\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076938957 W= 0.251116 b= 0.806369\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076934069 W= 0.250301 b= 0.806262\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076936863 W= 0.250139 b= 0.806187\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076941378 W= 0.251213 b= 0.806339\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076934353 W= 0.250882 b= 0.806309\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076967582 W= 0.249353 b= 0.806021\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076945230 W= 0.249841 b= 0.806082\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076932371 W= 0.250511 b= 0.8062\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076960221 W= 0.249484 b= 0.806089\n",
      "迭代次数Epoch: 1850 下降值cost= 0.076992922 W= 0.248974 b= 0.805925\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076982439 W= 0.249151 b= 0.805704\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076945677 W= 0.251372 b= 0.806209\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076936699 W= 0.251053 b= 0.806151\n",
      "迭代次数Epoch: 1900 下降值cost= 0.077169225 W= 0.253813 b= 0.806562\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076934882 W= 0.25026 b= 0.806049\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076956600 W= 0.249583 b= 0.805887\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076934859 W= 0.25027 b= 0.805957\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076938704 W= 0.251153 b= 0.8061\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076933838 W= 0.250339 b= 0.805993\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076936595 W= 0.250177 b= 0.805918\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076941133 W= 0.251251 b= 0.80607\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076934092 W= 0.250919 b= 0.80604\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076967381 W= 0.24939 b= 0.805752\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076945022 W= 0.249879 b= 0.805813\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076932132 W= 0.250548 b= 0.805931\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076960020 W= 0.24952 b= 0.805821\n",
      "迭代次数Epoch: 1900 下降值cost= 0.076992728 W= 0.249011 b= 0.805656\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076982230 W= 0.249187 b= 0.805452\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076945469 W= 0.251408 b= 0.805957\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076936468 W= 0.251089 b= 0.805898\n",
      "迭代次数Epoch: 1950 下降值cost= 0.077169083 W= 0.253849 b= 0.80631\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076934651 W= 0.250296 b= 0.805797\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076956339 W= 0.249619 b= 0.805635\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076934636 W= 0.250306 b= 0.805705\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076938517 W= 0.251189 b= 0.805848\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076933600 W= 0.250375 b= 0.805741\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076936372 W= 0.250213 b= 0.805666\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076940931 W= 0.251287 b= 0.805818\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076933891 W= 0.250954 b= 0.805787\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076967180 W= 0.249425 b= 0.8055\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076944806 W= 0.249914 b= 0.805561\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076931916 W= 0.250584 b= 0.805679\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076959834 W= 0.249555 b= 0.805568\n",
      "迭代次数Epoch: 1950 下降值cost= 0.076992534 W= 0.249046 b= 0.805404\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076982051 W= 0.24922 b= 0.805213\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076945253 W= 0.251442 b= 0.805717\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076936282 W= 0.251122 b= 0.805659\n",
      "迭代次数Epoch: 2000 下降值cost= 0.077168889 W= 0.253883 b= 0.806071\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076934449 W= 0.25033 b= 0.805558\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076956123 W= 0.249653 b= 0.805396\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076934427 W= 0.250339 b= 0.805466\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076938286 W= 0.251223 b= 0.805609\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076933399 W= 0.250409 b= 0.805502\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076936156 W= 0.250246 b= 0.805427\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076940730 W= 0.251321 b= 0.805579\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076933652 W= 0.250987 b= 0.805548\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076967001 W= 0.249459 b= 0.805261\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076944642 W= 0.249947 b= 0.805322\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076931730 W= 0.250617 b= 0.80544\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076959670 W= 0.249588 b= 0.805329\n",
      "迭代次数Epoch: 2000 下降值cost= 0.076992378 W= 0.249079 b= 0.805165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 2050 下降值cost= 0.076981880 W= 0.249251 b= 0.804992\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076945074 W= 0.251473 b= 0.805497\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076936103 W= 0.251154 b= 0.805439\n",
      "迭代次数Epoch: 2050 下降值cost= 0.077168748 W= 0.253914 b= 0.805851\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076934248 W= 0.250361 b= 0.805338\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076955922 W= 0.249685 b= 0.805176\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076934256 W= 0.25037 b= 0.805246\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076938123 W= 0.251254 b= 0.805389\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076933220 W= 0.25044 b= 0.805281\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076935977 W= 0.250278 b= 0.805207\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076940574 W= 0.251352 b= 0.805359\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076933488 W= 0.251018 b= 0.805328\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076966830 W= 0.249489 b= 0.805041\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076944470 W= 0.249978 b= 0.805102\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076931544 W= 0.250648 b= 0.80522\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076959535 W= 0.249619 b= 0.805109\n",
      "迭代次数Epoch: 2050 下降值cost= 0.076992251 W= 0.24911 b= 0.804945\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076981753 W= 0.24928 b= 0.804783\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076944903 W= 0.251502 b= 0.805288\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076935932 W= 0.251183 b= 0.80523\n",
      "迭代次数Epoch: 2100 下降值cost= 0.077168621 W= 0.253944 b= 0.805641\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076934084 W= 0.250391 b= 0.805129\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076955721 W= 0.249715 b= 0.804967\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076934092 W= 0.2504 b= 0.805037\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076937966 W= 0.251284 b= 0.80518\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076933056 W= 0.250469 b= 0.805072\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076935820 W= 0.250307 b= 0.804998\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076940395 W= 0.251382 b= 0.80515\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076933309 W= 0.251046 b= 0.805119\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076966703 W= 0.249518 b= 0.804832\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076944292 W= 0.250007 b= 0.804893\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076931395 W= 0.250677 b= 0.805011\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076959401 W= 0.249648 b= 0.8049\n",
      "迭代次数Epoch: 2100 下降值cost= 0.076992102 W= 0.249139 b= 0.804736\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076981604 W= 0.249307 b= 0.804591\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076944768 W= 0.251529 b= 0.805096\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076935790 W= 0.25121 b= 0.805038\n",
      "迭代次数Epoch: 2150 下降值cost= 0.077168480 W= 0.253971 b= 0.80545\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076933920 W= 0.250418 b= 0.804937\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076955557 W= 0.249742 b= 0.804775\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076933935 W= 0.250427 b= 0.804845\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076937802 W= 0.251311 b= 0.804988\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076932915 W= 0.250496 b= 0.804881\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076935664 W= 0.250335 b= 0.804806\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076940246 W= 0.251409 b= 0.804959\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076933146 W= 0.251073 b= 0.804927\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076966576 W= 0.249545 b= 0.80464\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076944180 W= 0.250033 b= 0.804701\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076931246 W= 0.250704 b= 0.80482\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076959282 W= 0.249674 b= 0.804708\n",
      "迭代次数Epoch: 2150 下降值cost= 0.076991990 W= 0.249166 b= 0.804545\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076981470 W= 0.249333 b= 0.804409\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076944627 W= 0.251555 b= 0.804914\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076935656 W= 0.251236 b= 0.804856\n",
      "迭代次数Epoch: 2200 下降值cost= 0.077168405 W= 0.253997 b= 0.805267\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076933809 W= 0.250444 b= 0.804755\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076955408 W= 0.249769 b= 0.804593\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076933801 W= 0.250453 b= 0.804663\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076937661 W= 0.251336 b= 0.804806\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076932766 W= 0.250522 b= 0.804698\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076935537 W= 0.250361 b= 0.804624\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076940119 W= 0.251435 b= 0.804776\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076933019 W= 0.251098 b= 0.804745\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076966457 W= 0.249571 b= 0.804458\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076944076 W= 0.250058 b= 0.804519\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076931097 W= 0.250729 b= 0.804637\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076959163 W= 0.249699 b= 0.804526\n",
      "迭代次数Epoch: 2200 下降值cost= 0.076991878 W= 0.249191 b= 0.804362\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076981373 W= 0.249357 b= 0.804237\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076944493 W= 0.251579 b= 0.804742\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076935522 W= 0.251261 b= 0.804684\n",
      "迭代次数Epoch: 2250 下降值cost= 0.077168278 W= 0.254021 b= 0.805095\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076933667 W= 0.250469 b= 0.804583\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076955266 W= 0.249793 b= 0.804421\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076933682 W= 0.250477 b= 0.80449\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076937534 W= 0.251361 b= 0.804633\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076932654 W= 0.250546 b= 0.804526\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076935410 W= 0.250385 b= 0.804452\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076940000 W= 0.251459 b= 0.804604\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076932870 W= 0.251122 b= 0.804573\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076966360 W= 0.249594 b= 0.804285\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076943956 W= 0.250082 b= 0.804346\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076930985 W= 0.250753 b= 0.804465\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076959074 W= 0.249723 b= 0.804354\n",
      "迭代次数Epoch: 2250 下降值cost= 0.076991782 W= 0.249215 b= 0.80419\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076981276 W= 0.24938 b= 0.804075\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076944388 W= 0.251602 b= 0.80458\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076935418 W= 0.251284 b= 0.804522\n",
      "迭代次数Epoch: 2300 下降值cost= 0.077168182 W= 0.254044 b= 0.804933\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076933563 W= 0.250492 b= 0.804421\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076955140 W= 0.249816 b= 0.804259\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076933570 W= 0.2505 b= 0.804328\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076937452 W= 0.251384 b= 0.804471\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076932527 W= 0.250569 b= 0.804364\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076935276 W= 0.250408 b= 0.80429\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076939896 W= 0.251482 b= 0.804442\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076932751 W= 0.251145 b= 0.804411\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076966263 W= 0.249617 b= 0.804123\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076943845 W= 0.250105 b= 0.804184\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076930881 W= 0.250776 b= 0.804303\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076958984 W= 0.249745 b= 0.804192\n",
      "迭代次数Epoch: 2300 下降值cost= 0.076991685 W= 0.249238 b= 0.804028\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076981187 W= 0.249401 b= 0.803922\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076944269 W= 0.251624 b= 0.804427\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076935329 W= 0.251305 b= 0.804369\n",
      "迭代次数Epoch: 2350 下降值cost= 0.077168100 W= 0.254066 b= 0.804781\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076933451 W= 0.250513 b= 0.804268\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076955020 W= 0.249838 b= 0.804106\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076933444 W= 0.250521 b= 0.804176\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076937333 W= 0.251405 b= 0.804319\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076932430 W= 0.25059 b= 0.804211\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076935180 W= 0.250429 b= 0.804137\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076939799 W= 0.251504 b= 0.80429\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076932654 W= 0.251166 b= 0.804258\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076966174 W= 0.249638 b= 0.803971\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076943770 W= 0.250126 b= 0.804032\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076930769 W= 0.250797 b= 0.804151\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076958917 W= 0.249766 b= 0.804039\n",
      "迭代次数Epoch: 2350 下降值cost= 0.076991618 W= 0.249259 b= 0.803876\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076981090 W= 0.249422 b= 0.803775\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076944172 W= 0.251644 b= 0.804281\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076935232 W= 0.251326 b= 0.804223\n",
      "迭代次数Epoch: 2400 下降值cost= 0.077168018 W= 0.254087 b= 0.804634\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076933324 W= 0.250534 b= 0.804121\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076954901 W= 0.249859 b= 0.80396\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076933384 W= 0.250542 b= 0.804029\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076937236 W= 0.251426 b= 0.804172\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076932326 W= 0.250611 b= 0.804065\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076935090 W= 0.25045 b= 0.803991\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076939709 W= 0.251525 b= 0.804143\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076932557 W= 0.251186 b= 0.804112\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076966099 W= 0.249659 b= 0.803824\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076943688 W= 0.250146 b= 0.803885\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076930664 W= 0.250817 b= 0.804004\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076958835 W= 0.249786 b= 0.803893\n",
      "迭代次数Epoch: 2400 下降值cost= 0.076991543 W= 0.249279 b= 0.803729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 2450 下降值cost= 0.076981023 W= 0.24944 b= 0.803642\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076944083 W= 0.251663 b= 0.804147\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076935142 W= 0.251345 b= 0.804089\n",
      "迭代次数Epoch: 2450 下降值cost= 0.077167973 W= 0.254106 b= 0.804501\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076933235 W= 0.250553 b= 0.803988\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076954804 W= 0.249878 b= 0.803826\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076933287 W= 0.250561 b= 0.803896\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076937139 W= 0.251445 b= 0.804039\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076932251 W= 0.25063 b= 0.803932\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076934978 W= 0.250469 b= 0.803858\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076939628 W= 0.251544 b= 0.80401\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076932460 W= 0.251204 b= 0.803979\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076966025 W= 0.249677 b= 0.803691\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076943614 W= 0.250165 b= 0.803752\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076930590 W= 0.250836 b= 0.803871\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076958776 W= 0.249805 b= 0.80376\n",
      "迭代次数Epoch: 2450 下降值cost= 0.076991491 W= 0.249298 b= 0.803596\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076980948 W= 0.249458 b= 0.803516\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076944016 W= 0.251681 b= 0.804021\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076935053 W= 0.251363 b= 0.803964\n",
      "迭代次数Epoch: 2500 下降值cost= 0.077167891 W= 0.254124 b= 0.804375\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076933183 W= 0.250571 b= 0.803862\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076954715 W= 0.249896 b= 0.803701\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076933205 W= 0.250578 b= 0.80377\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076937072 W= 0.251462 b= 0.803913\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076932169 W= 0.250648 b= 0.803806\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076934911 W= 0.250487 b= 0.803732\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076939546 W= 0.251561 b= 0.803884\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076932371 W= 0.251222 b= 0.803853\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076965943 W= 0.249695 b= 0.803566\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076943547 W= 0.250182 b= 0.803627\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076930515 W= 0.250854 b= 0.803745\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076958708 W= 0.249822 b= 0.803634\n",
      "迭代次数Epoch: 2500 下降值cost= 0.076991424 W= 0.249315 b= 0.80347\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076980889 W= 0.249475 b= 0.803397\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076943934 W= 0.251698 b= 0.803902\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076934986 W= 0.25138 b= 0.803845\n",
      "迭代次数Epoch: 2550 下降值cost= 0.077167839 W= 0.25414 b= 0.804256\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076933086 W= 0.250588 b= 0.803743\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076954633 W= 0.249913 b= 0.803582\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076933131 W= 0.250595 b= 0.803651\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076937012 W= 0.251479 b= 0.803794\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076932088 W= 0.250664 b= 0.803687\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076934837 W= 0.250504 b= 0.803613\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076939479 W= 0.251578 b= 0.803765\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076932319 W= 0.251238 b= 0.803734\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076965891 W= 0.249711 b= 0.803447\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076943472 W= 0.250199 b= 0.803508\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076930448 W= 0.25087 b= 0.803626\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076958649 W= 0.249839 b= 0.803515\n",
      "迭代次数Epoch: 2550 下降值cost= 0.076991379 W= 0.249332 b= 0.803351\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076980837 W= 0.24949 b= 0.803284\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076943859 W= 0.251714 b= 0.803789\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076934919 W= 0.251396 b= 0.803732\n",
      "迭代次数Epoch: 2600 下降值cost= 0.077167794 W= 0.254157 b= 0.804143\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076933019 W= 0.250604 b= 0.80363\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076954544 W= 0.249929 b= 0.803469\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076933049 W= 0.250611 b= 0.803538\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076936938 W= 0.251495 b= 0.803681\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076932020 W= 0.25068 b= 0.803574\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076934777 W= 0.25052 b= 0.8035\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076939404 W= 0.251594 b= 0.803652\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076932237 W= 0.251254 b= 0.803621\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076965831 W= 0.249727 b= 0.803334\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076943427 W= 0.250215 b= 0.803394\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076930381 W= 0.250886 b= 0.803513\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076958597 W= 0.249854 b= 0.803402\n",
      "迭代次数Epoch: 2600 下降值cost= 0.076991320 W= 0.249347 b= 0.803238\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076980785 W= 0.249505 b= 0.803179\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076943800 W= 0.251728 b= 0.803684\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076934859 W= 0.251411 b= 0.803627\n",
      "迭代次数Epoch: 2650 下降值cost= 0.077167735 W= 0.254171 b= 0.804038\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076932959 W= 0.250619 b= 0.803525\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076954491 W= 0.249944 b= 0.803364\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076932997 W= 0.250626 b= 0.803433\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076936871 W= 0.25151 b= 0.803576\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076931968 W= 0.250695 b= 0.803469\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076934718 W= 0.250535 b= 0.803395\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076939352 W= 0.251609 b= 0.803547\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076932169 W= 0.251269 b= 0.803516\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076965779 W= 0.249742 b= 0.803228\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076943368 W= 0.250229 b= 0.803289\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076930329 W= 0.250901 b= 0.803408\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076958552 W= 0.249869 b= 0.803297\n",
      "迭代次数Epoch: 2650 下降值cost= 0.076991275 W= 0.249362 b= 0.803133\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076980725 W= 0.24952 b= 0.803077\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076943733 W= 0.251743 b= 0.803582\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076934800 W= 0.251425 b= 0.803524\n",
      "迭代次数Epoch: 2700 下降值cost= 0.077167697 W= 0.254186 b= 0.803936\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076932907 W= 0.250634 b= 0.803423\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076954417 W= 0.249959 b= 0.803261\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076932952 W= 0.25064 b= 0.803331\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076936826 W= 0.251525 b= 0.803474\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076931894 W= 0.25071 b= 0.803366\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076934636 W= 0.250549 b= 0.803292\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076939315 W= 0.251624 b= 0.803445\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076932110 W= 0.251283 b= 0.803413\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076965734 W= 0.249756 b= 0.803126\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076943316 W= 0.250243 b= 0.803187\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076930262 W= 0.250915 b= 0.803306\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076958515 W= 0.249883 b= 0.803194\n",
      "迭代次数Epoch: 2700 下降值cost= 0.076991253 W= 0.249376 b= 0.803031\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076980673 W= 0.249533 b= 0.802978\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076943688 W= 0.251757 b= 0.803484\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076934755 W= 0.251439 b= 0.803426\n",
      "迭代次数Epoch: 2750 下降值cost= 0.077167653 W= 0.2542 b= 0.803837\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076932833 W= 0.250647 b= 0.803325\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076954357 W= 0.249973 b= 0.803163\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076932892 W= 0.250654 b= 0.803233\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076936774 W= 0.251538 b= 0.803376\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076931864 W= 0.250723 b= 0.803268\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076934591 W= 0.250563 b= 0.803195\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076939248 W= 0.251638 b= 0.803347\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076932043 W= 0.251296 b= 0.803315\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076965705 W= 0.24977 b= 0.803028\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076943278 W= 0.250257 b= 0.803089\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076930225 W= 0.250929 b= 0.803208\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076958477 W= 0.249896 b= 0.803096\n",
      "迭代次数Epoch: 2750 下降值cost= 0.076991200 W= 0.24939 b= 0.802933\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076980628 W= 0.249546 b= 0.80289\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076943658 W= 0.251769 b= 0.803395\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076934680 W= 0.251452 b= 0.803337\n",
      "迭代次数Epoch: 2800 下降值cost= 0.077167623 W= 0.254213 b= 0.803749\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076932788 W= 0.25066 b= 0.803236\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076954290 W= 0.249986 b= 0.803074\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076932833 W= 0.250666 b= 0.803144\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076936707 W= 0.251551 b= 0.803287\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076931775 W= 0.250736 b= 0.80318\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076934524 W= 0.250576 b= 0.803106\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076939195 W= 0.25165 b= 0.803258\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076932006 W= 0.251309 b= 0.803227\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076965645 W= 0.249782 b= 0.802939\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076943219 W= 0.250269 b= 0.803\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076930158 W= 0.250941 b= 0.803119\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076958448 W= 0.249909 b= 0.803008\n",
      "迭代次数Epoch: 2800 下降值cost= 0.076991148 W= 0.249402 b= 0.802844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 2850 下降值cost= 0.076980598 W= 0.249557 b= 0.802809\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076943591 W= 0.251781 b= 0.803314\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076934643 W= 0.251463 b= 0.803257\n",
      "迭代次数Epoch: 2850 下降值cost= 0.077167578 W= 0.254224 b= 0.803668\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076932743 W= 0.250672 b= 0.803155\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076954231 W= 0.249997 b= 0.802994\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076932795 W= 0.250678 b= 0.803063\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076936670 W= 0.251562 b= 0.803206\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076931760 W= 0.250747 b= 0.803099\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076934502 W= 0.250587 b= 0.803025\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076939158 W= 0.251662 b= 0.803178\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076931931 W= 0.25132 b= 0.803146\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076965615 W= 0.249793 b= 0.802859\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076943196 W= 0.25028 b= 0.80292\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076930121 W= 0.250952 b= 0.803038\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076958410 W= 0.24992 b= 0.802927\n",
      "迭代次数Epoch: 2850 下降值cost= 0.076991133 W= 0.249413 b= 0.802764\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076980561 W= 0.249568 b= 0.802734\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076943561 W= 0.251791 b= 0.803239\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076934613 W= 0.251474 b= 0.803181\n",
      "迭代次数Epoch: 2900 下降值cost= 0.077167556 W= 0.254235 b= 0.803593\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076932698 W= 0.250682 b= 0.80308\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076954186 W= 0.250008 b= 0.802918\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076932751 W= 0.250688 b= 0.802988\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076936632 W= 0.251573 b= 0.803131\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076931722 W= 0.250758 b= 0.803024\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076934457 W= 0.250598 b= 0.80295\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076939128 W= 0.251672 b= 0.803102\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076931894 W= 0.25133 b= 0.803071\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076965585 W= 0.249804 b= 0.802783\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076943181 W= 0.250291 b= 0.802844\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076930076 W= 0.250963 b= 0.802963\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076958388 W= 0.24993 b= 0.802852\n",
      "迭代次数Epoch: 2900 下降值cost= 0.076991111 W= 0.249424 b= 0.802689\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076980531 W= 0.249578 b= 0.802663\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076943524 W= 0.251801 b= 0.803168\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076934576 W= 0.251484 b= 0.803111\n",
      "迭代次数Epoch: 2950 下降值cost= 0.077167526 W= 0.254245 b= 0.803522\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076932669 W= 0.250692 b= 0.80301\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076954134 W= 0.250018 b= 0.802848\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076932713 W= 0.250698 b= 0.802917\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076936595 W= 0.251583 b= 0.803061\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076931670 W= 0.250768 b= 0.802953\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076934420 W= 0.250608 b= 0.802879\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076939084 W= 0.251682 b= 0.803032\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076931879 W= 0.25134 b= 0.803\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076965533 W= 0.249814 b= 0.802713\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076943122 W= 0.250301 b= 0.802774\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076930046 W= 0.250973 b= 0.802893\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076958358 W= 0.24994 b= 0.802781\n",
      "迭代次数Epoch: 2950 下降值cost= 0.076991089 W= 0.249434 b= 0.802618\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076980494 W= 0.249587 b= 0.802597\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076943472 W= 0.251811 b= 0.803102\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076934539 W= 0.251493 b= 0.803044\n",
      "迭代次数Epoch: 3000 下降值cost= 0.077167511 W= 0.254254 b= 0.803456\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076932617 W= 0.250702 b= 0.802943\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076954097 W= 0.250028 b= 0.802782\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076932684 W= 0.250708 b= 0.802851\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076936550 W= 0.251592 b= 0.802994\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076931648 W= 0.250777 b= 0.802887\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076934375 W= 0.250618 b= 0.802813\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076939054 W= 0.251692 b= 0.802966\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076931834 W= 0.251349 b= 0.802934\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076965526 W= 0.249823 b= 0.802646\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076943099 W= 0.25031 b= 0.802707\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076930001 W= 0.250982 b= 0.802826\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076958328 W= 0.249949 b= 0.802715\n",
      "迭代次数Epoch: 3000 下降值cost= 0.076991051 W= 0.249443 b= 0.802552\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076980479 W= 0.249596 b= 0.802531\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076943442 W= 0.25182 b= 0.803036\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076934516 W= 0.251503 b= 0.802979\n",
      "迭代次数Epoch: 3050 下降值cost= 0.077167451 W= 0.254263 b= 0.80339\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076932587 W= 0.250711 b= 0.802877\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076954059 W= 0.250037 b= 0.802716\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076932661 W= 0.250717 b= 0.802785\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076936536 W= 0.251602 b= 0.802928\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076931611 W= 0.250786 b= 0.802821\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076934360 W= 0.250627 b= 0.802747\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076939024 W= 0.251701 b= 0.8029\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076931790 W= 0.251358 b= 0.802868\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076965511 W= 0.249832 b= 0.802581\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076943085 W= 0.250319 b= 0.802642\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076929986 W= 0.250991 b= 0.802761\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076958299 W= 0.249958 b= 0.802649\n",
      "迭代次数Epoch: 3050 下降值cost= 0.076991051 W= 0.249452 b= 0.802486\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076980442 W= 0.249604 b= 0.802471\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076943405 W= 0.251828 b= 0.802977\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076934487 W= 0.251511 b= 0.802919\n",
      "迭代次数Epoch: 3100 下降值cost= 0.077167451 W= 0.254272 b= 0.803331\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076932549 W= 0.25072 b= 0.802818\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076954037 W= 0.250046 b= 0.802656\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076932617 W= 0.250725 b= 0.802726\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076936491 W= 0.25161 b= 0.802869\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076931573 W= 0.250795 b= 0.802761\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076934330 W= 0.250635 b= 0.802688\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076938987 W= 0.251709 b= 0.80284\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076931767 W= 0.251366 b= 0.802809\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076965481 W= 0.24984 b= 0.802521\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076943055 W= 0.250327 b= 0.802582\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076929942 W= 0.250999 b= 0.802701\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076958299 W= 0.249966 b= 0.80259\n",
      "迭代次数Epoch: 3100 下降值cost= 0.076991022 W= 0.24946 b= 0.802426\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076980419 W= 0.249612 b= 0.802414\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076943375 W= 0.251836 b= 0.802919\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076934457 W= 0.251519 b= 0.802862\n",
      "迭代次数Epoch: 3150 下降值cost= 0.077167436 W= 0.25428 b= 0.803273\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076932527 W= 0.250728 b= 0.80276\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076954000 W= 0.250054 b= 0.802599\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076932609 W= 0.250733 b= 0.802668\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076936476 W= 0.251618 b= 0.802811\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076931544 W= 0.250803 b= 0.802704\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076934285 W= 0.250643 b= 0.80263\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076938964 W= 0.251718 b= 0.802783\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076931730 W= 0.251374 b= 0.802751\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076965459 W= 0.249848 b= 0.802464\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076943032 W= 0.250335 b= 0.802525\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076929927 W= 0.251007 b= 0.802643\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076958269 W= 0.249974 b= 0.802532\n",
      "迭代次数Epoch: 3150 下降值cost= 0.076990984 W= 0.249468 b= 0.802369\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076980397 W= 0.24962 b= 0.802357\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076943353 W= 0.251844 b= 0.802863\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076934412 W= 0.251527 b= 0.802805\n",
      "迭代次数Epoch: 3200 下降值cost= 0.077167407 W= 0.254288 b= 0.803216\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076932497 W= 0.250736 b= 0.802704\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076953955 W= 0.250062 b= 0.802542\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076932572 W= 0.250741 b= 0.802612\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076936439 W= 0.251626 b= 0.802755\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076931529 W= 0.250811 b= 0.802647\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076934263 W= 0.250651 b= 0.802574\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076938935 W= 0.251726 b= 0.802726\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076931708 W= 0.251382 b= 0.802694\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076965436 W= 0.249856 b= 0.802407\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076943010 W= 0.250343 b= 0.802468\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076929890 W= 0.251015 b= 0.802587\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076958247 W= 0.249982 b= 0.802475\n",
      "迭代次数Epoch: 3200 下降值cost= 0.076990984 W= 0.249476 b= 0.802312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 3250 下降值cost= 0.076980382 W= 0.249628 b= 0.802305\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076943323 W= 0.251852 b= 0.80281\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076934397 W= 0.251535 b= 0.802752\n",
      "迭代次数Epoch: 3250 下降值cost= 0.077167384 W= 0.254296 b= 0.803164\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076932468 W= 0.250743 b= 0.802651\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076953948 W= 0.25007 b= 0.80249\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076932535 W= 0.250749 b= 0.802559\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076936424 W= 0.251634 b= 0.802702\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076931506 W= 0.250818 b= 0.802595\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076934226 W= 0.250659 b= 0.802521\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076938927 W= 0.251733 b= 0.802674\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076931678 W= 0.25139 b= 0.802642\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076965421 W= 0.249864 b= 0.802355\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076942988 W= 0.25035 b= 0.802416\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076929867 W= 0.251023 b= 0.802535\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076958232 W= 0.249989 b= 0.802423\n",
      "迭代次数Epoch: 3250 下降值cost= 0.076990969 W= 0.249483 b= 0.80226\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076980360 W= 0.249634 b= 0.80226\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076943316 W= 0.251858 b= 0.802765\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076934397 W= 0.251541 b= 0.802707\n",
      "迭代次数Epoch: 3300 下降值cost= 0.077167384 W= 0.254302 b= 0.803119\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076932453 W= 0.25075 b= 0.802606\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076953903 W= 0.250076 b= 0.802445\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076932535 W= 0.250755 b= 0.802514\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076936401 W= 0.25164 b= 0.802657\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076931477 W= 0.250825 b= 0.80255\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076934218 W= 0.250665 b= 0.802476\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076938905 W= 0.25174 b= 0.802629\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076931655 W= 0.251396 b= 0.802597\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076965399 W= 0.24987 b= 0.80231\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076942958 W= 0.250357 b= 0.802371\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076929837 W= 0.251029 b= 0.80249\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076958239 W= 0.249995 b= 0.802378\n",
      "迭代次数Epoch: 3300 下降值cost= 0.076990947 W= 0.24949 b= 0.802215\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076980338 W= 0.24964 b= 0.802215\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076943301 W= 0.251865 b= 0.80272\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076934367 W= 0.251548 b= 0.802663\n",
      "迭代次数Epoch: 3350 下降值cost= 0.077167362 W= 0.254308 b= 0.803074\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076932415 W= 0.250756 b= 0.802562\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076953880 W= 0.250082 b= 0.8024\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076932497 W= 0.250761 b= 0.802469\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076936364 W= 0.251646 b= 0.802613\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076931462 W= 0.250831 b= 0.802505\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076934181 W= 0.250672 b= 0.802432\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076938890 W= 0.251746 b= 0.802584\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076931633 W= 0.251402 b= 0.802552\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076965377 W= 0.249876 b= 0.802265\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076942928 W= 0.250363 b= 0.802326\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076929830 W= 0.251035 b= 0.802445\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076958217 W= 0.250002 b= 0.802333\n",
      "迭代次数Epoch: 3350 下降值cost= 0.076990925 W= 0.249496 b= 0.80217\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076980330 W= 0.249647 b= 0.80217\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076943271 W= 0.251871 b= 0.802675\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076934345 W= 0.251554 b= 0.802617\n",
      "迭代次数Epoch: 3400 下降值cost= 0.077167355 W= 0.254315 b= 0.803029\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076932393 W= 0.250762 b= 0.802516\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076953851 W= 0.250089 b= 0.802355\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076932475 W= 0.250768 b= 0.802424\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076936364 W= 0.251653 b= 0.802567\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076931424 W= 0.250837 b= 0.80246\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076934166 W= 0.250678 b= 0.802386\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076938860 W= 0.251752 b= 0.802539\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076931611 W= 0.251408 b= 0.802507\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076965369 W= 0.249882 b= 0.80222\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076942921 W= 0.250369 b= 0.802281\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076929800 W= 0.251041 b= 0.8024\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076958194 W= 0.250008 b= 0.802288\n",
      "迭代次数Epoch: 3400 下降值cost= 0.076990910 W= 0.249502 b= 0.802125\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076980300 W= 0.249653 b= 0.802127\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076943234 W= 0.251877 b= 0.802632\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076934315 W= 0.25156 b= 0.802575\n",
      "迭代次数Epoch: 3450 下降值cost= 0.077167340 W= 0.254321 b= 0.802986\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076932378 W= 0.250769 b= 0.802473\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076953828 W= 0.250095 b= 0.802312\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076932445 W= 0.250774 b= 0.802381\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076936349 W= 0.251659 b= 0.802524\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076931424 W= 0.250843 b= 0.802417\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076934159 W= 0.250684 b= 0.802343\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076938838 W= 0.251758 b= 0.802496\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076931588 W= 0.251414 b= 0.802464\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076965362 W= 0.249888 b= 0.802177\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076942898 W= 0.250375 b= 0.802238\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076929778 W= 0.251047 b= 0.802357\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076958179 W= 0.250014 b= 0.802245\n",
      "迭代次数Epoch: 3450 下降值cost= 0.076990910 W= 0.249508 b= 0.802082\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076980293 W= 0.249658 b= 0.802091\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076943219 W= 0.251882 b= 0.802596\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076934293 W= 0.251565 b= 0.802539\n",
      "迭代次数Epoch: 3500 下降值cost= 0.077167325 W= 0.254326 b= 0.80295\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076932363 W= 0.250774 b= 0.802437\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076953821 W= 0.2501 b= 0.802276\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076932445 W= 0.250779 b= 0.802345\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076936312 W= 0.251664 b= 0.802488\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076931417 W= 0.250848 b= 0.802381\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076934129 W= 0.250689 b= 0.802307\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076938830 W= 0.251763 b= 0.80246\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076931566 W= 0.251419 b= 0.802428\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076965339 W= 0.249893 b= 0.802141\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076942906 W= 0.25038 b= 0.802202\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076929756 W= 0.251052 b= 0.802321\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076958157 W= 0.250019 b= 0.802209\n",
      "迭代次数Epoch: 3500 下降值cost= 0.076990902 W= 0.249513 b= 0.802046\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076980293 W= 0.249662 b= 0.802058\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076943219 W= 0.251887 b= 0.802563\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076934308 W= 0.25157 b= 0.802506\n",
      "迭代次数Epoch: 3550 下降值cost= 0.077167317 W= 0.254331 b= 0.802917\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076932356 W= 0.250778 b= 0.802405\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076953791 W= 0.250105 b= 0.802243\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076932438 W= 0.250784 b= 0.802313\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076936305 W= 0.251669 b= 0.802456\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076931387 W= 0.250853 b= 0.802348\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076934122 W= 0.250694 b= 0.802275\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076938815 W= 0.251768 b= 0.802427\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076931551 W= 0.251424 b= 0.802395\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076965325 W= 0.249898 b= 0.802108\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076942883 W= 0.250385 b= 0.802169\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076929756 W= 0.251057 b= 0.802288\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076958165 W= 0.250023 b= 0.802177\n",
      "迭代次数Epoch: 3550 下降值cost= 0.076990902 W= 0.249518 b= 0.802013\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076980278 W= 0.249667 b= 0.802026\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076943204 W= 0.251891 b= 0.802532\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076934278 W= 0.251574 b= 0.802474\n",
      "迭代次数Epoch: 3600 下降值cost= 0.077167317 W= 0.254335 b= 0.802885\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076932333 W= 0.250783 b= 0.802373\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076953776 W= 0.250109 b= 0.802211\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076932423 W= 0.250788 b= 0.802281\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076936297 W= 0.251673 b= 0.802424\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076931380 W= 0.250858 b= 0.802316\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076934092 W= 0.250698 b= 0.802243\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076938801 W= 0.251773 b= 0.802395\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076931536 W= 0.251428 b= 0.802364\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076965332 W= 0.249902 b= 0.802076\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076942883 W= 0.250389 b= 0.802137\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076929748 W= 0.251061 b= 0.802256\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076958165 W= 0.250028 b= 0.802145\n",
      "迭代次数Epoch: 3600 下降值cost= 0.076990895 W= 0.249522 b= 0.801982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 3650 下降值cost= 0.076980263 W= 0.249671 b= 0.801996\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076943204 W= 0.251895 b= 0.802502\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076934278 W= 0.251579 b= 0.802444\n",
      "迭代次数Epoch: 3650 下降值cost= 0.077167317 W= 0.254339 b= 0.802856\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076932341 W= 0.250787 b= 0.802343\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076953746 W= 0.250114 b= 0.802181\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076932408 W= 0.250792 b= 0.802251\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076936282 W= 0.251677 b= 0.802394\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076931365 W= 0.250862 b= 0.802287\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076934084 W= 0.250703 b= 0.802213\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076938793 W= 0.251777 b= 0.802366\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076931536 W= 0.251432 b= 0.802334\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076965302 W= 0.249907 b= 0.802047\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076942869 W= 0.250393 b= 0.802107\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076929741 W= 0.251066 b= 0.802226\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076958150 W= 0.250032 b= 0.802115\n",
      "迭代次数Epoch: 3650 下降值cost= 0.076990873 W= 0.249526 b= 0.801952\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076980256 W= 0.249675 b= 0.801967\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076943159 W= 0.2519 b= 0.802472\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076934248 W= 0.251583 b= 0.802415\n",
      "迭代次数Epoch: 3700 下降值cost= 0.077167280 W= 0.254344 b= 0.802826\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076932319 W= 0.250791 b= 0.802314\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076953746 W= 0.250118 b= 0.802152\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076932378 W= 0.250796 b= 0.802221\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076936260 W= 0.251681 b= 0.802365\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076931350 W= 0.250866 b= 0.802257\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076934077 W= 0.250707 b= 0.802184\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076938771 W= 0.251781 b= 0.802336\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076931514 W= 0.251436 b= 0.802304\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076965302 W= 0.249911 b= 0.802017\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076942861 W= 0.250397 b= 0.802078\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076929718 W= 0.25107 b= 0.802197\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076958157 W= 0.250036 b= 0.802085\n",
      "迭代次数Epoch: 3700 下降值cost= 0.076990858 W= 0.24953 b= 0.801922\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076980241 W= 0.249678 b= 0.801943\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076943159 W= 0.251903 b= 0.802449\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076934241 W= 0.251586 b= 0.802391\n",
      "迭代次数Epoch: 3750 下降值cost= 0.077167273 W= 0.254347 b= 0.802802\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076932296 W= 0.250795 b= 0.80229\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076953739 W= 0.250121 b= 0.802128\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076932378 W= 0.2508 b= 0.802198\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076936252 W= 0.251685 b= 0.802341\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076931350 W= 0.250869 b= 0.802233\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076934062 W= 0.25071 b= 0.80216\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076938741 W= 0.251784 b= 0.802312\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076931506 W= 0.25144 b= 0.802281\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076965302 W= 0.249914 b= 0.801993\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076942854 W= 0.250401 b= 0.802054\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076929718 W= 0.251073 b= 0.802173\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076958142 W= 0.250039 b= 0.802062\n",
      "迭代次数Epoch: 3750 下降值cost= 0.076990873 W= 0.249534 b= 0.801899\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076980248 W= 0.249681 b= 0.801922\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076943152 W= 0.251906 b= 0.802428\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076934248 W= 0.251589 b= 0.80237\n",
      "迭代次数Epoch: 3800 下降值cost= 0.077167273 W= 0.25435 b= 0.802782\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076932281 W= 0.250798 b= 0.802269\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076953717 W= 0.250124 b= 0.802107\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076932371 W= 0.250803 b= 0.802177\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076936245 W= 0.251688 b= 0.80232\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076931320 W= 0.250872 b= 0.802213\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076934054 W= 0.250713 b= 0.802139\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076938748 W= 0.251787 b= 0.802292\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076931499 W= 0.251443 b= 0.80226\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076965272 W= 0.249917 b= 0.801973\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076942854 W= 0.250403 b= 0.802033\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076929703 W= 0.251076 b= 0.802152\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076958127 W= 0.250042 b= 0.802041\n",
      "迭代次数Epoch: 3800 下降值cost= 0.076990858 W= 0.249536 b= 0.801878\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076980233 W= 0.249684 b= 0.801901\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076943159 W= 0.251909 b= 0.802407\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076934233 W= 0.251592 b= 0.802349\n",
      "迭代次数Epoch: 3850 下降值cost= 0.077167265 W= 0.254353 b= 0.802761\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076932274 W= 0.2508 b= 0.802248\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076953717 W= 0.250127 b= 0.802087\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076932371 W= 0.250806 b= 0.802156\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076936238 W= 0.251691 b= 0.802299\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076931335 W= 0.250875 b= 0.802192\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076934040 W= 0.250716 b= 0.802118\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076938763 W= 0.25179 b= 0.802271\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076931499 W= 0.251445 b= 0.802239\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076965272 W= 0.24992 b= 0.801952\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076942839 W= 0.250406 b= 0.802013\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076929696 W= 0.251079 b= 0.802131\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076958120 W= 0.250045 b= 0.80202\n",
      "迭代次数Epoch: 3850 下降值cost= 0.076990873 W= 0.249539 b= 0.801857\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076980226 W= 0.249687 b= 0.801879\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076943159 W= 0.251912 b= 0.802384\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076934226 W= 0.251595 b= 0.802327\n",
      "迭代次数Epoch: 3900 下降值cost= 0.077167265 W= 0.254356 b= 0.802738\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076932259 W= 0.250804 b= 0.802226\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076953702 W= 0.250131 b= 0.802064\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076932356 W= 0.250809 b= 0.802134\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076936238 W= 0.251694 b= 0.802277\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076931320 W= 0.250878 b= 0.802169\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076934047 W= 0.250719 b= 0.802096\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076938748 W= 0.251794 b= 0.802248\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076931484 W= 0.251449 b= 0.802217\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076965272 W= 0.249923 b= 0.801929\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076942839 W= 0.250409 b= 0.80199\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076929703 W= 0.251082 b= 0.802109\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076958098 W= 0.250048 b= 0.801998\n",
      "迭代次数Epoch: 3900 下降值cost= 0.076990850 W= 0.249542 b= 0.801835\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076980211 W= 0.249691 b= 0.801854\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076943122 W= 0.251915 b= 0.80236\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076934211 W= 0.251599 b= 0.802302\n",
      "迭代次数Epoch: 3950 下降值cost= 0.077167280 W= 0.25436 b= 0.802714\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076932259 W= 0.250807 b= 0.802201\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076953687 W= 0.250134 b= 0.80204\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076932356 W= 0.250812 b= 0.802109\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076936215 W= 0.251697 b= 0.802252\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076931298 W= 0.250882 b= 0.802145\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076934040 W= 0.250723 b= 0.802072\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076938733 W= 0.251797 b= 0.802224\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076931469 W= 0.251452 b= 0.802192\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076965272 W= 0.249926 b= 0.801905\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076942839 W= 0.250413 b= 0.801966\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076929681 W= 0.251085 b= 0.802085\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076958090 W= 0.250051 b= 0.801973\n",
      "迭代次数Epoch: 3950 下降值cost= 0.076990843 W= 0.249546 b= 0.80181\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076980211 W= 0.249694 b= 0.80183\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076943107 W= 0.251919 b= 0.802336\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076934196 W= 0.251602 b= 0.802278\n",
      "迭代次数Epoch: 4000 下降值cost= 0.077167220 W= 0.254363 b= 0.802689\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076932237 W= 0.25081 b= 0.802177\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076953679 W= 0.250137 b= 0.802015\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076932363 W= 0.250815 b= 0.802085\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076936193 W= 0.2517 b= 0.802228\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076931298 W= 0.250885 b= 0.80212\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076934017 W= 0.250726 b= 0.802047\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076938719 W= 0.2518 b= 0.8022\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076931454 W= 0.251455 b= 0.802168\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076965272 W= 0.24993 b= 0.80188\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076942831 W= 0.250416 b= 0.801941\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076929666 W= 0.251089 b= 0.80206\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076958120 W= 0.250054 b= 0.801949\n",
      "迭代次数Epoch: 4000 下降值cost= 0.076990850 W= 0.249549 b= 0.801786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 4050 下降值cost= 0.076980188 W= 0.249697 b= 0.801811\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076943099 W= 0.251922 b= 0.802316\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076934189 W= 0.251605 b= 0.802259\n",
      "迭代次数Epoch: 4050 下降值cost= 0.077167265 W= 0.254366 b= 0.80267\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076932251 W= 0.250813 b= 0.802158\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076953657 W= 0.25014 b= 0.801996\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076932319 W= 0.250818 b= 0.802065\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076936208 W= 0.251703 b= 0.802209\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076931283 W= 0.250888 b= 0.802101\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076934002 W= 0.250729 b= 0.802028\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076938719 W= 0.251803 b= 0.80218\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076931439 W= 0.251458 b= 0.802148\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076965250 W= 0.249932 b= 0.801861\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076942816 W= 0.250419 b= 0.801922\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076929666 W= 0.251091 b= 0.802041\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076958098 W= 0.250057 b= 0.801929\n",
      "迭代次数Epoch: 4050 下降值cost= 0.076990813 W= 0.249552 b= 0.801766\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076980211 W= 0.249699 b= 0.801796\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076943107 W= 0.251924 b= 0.802301\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076934196 W= 0.251607 b= 0.802244\n",
      "迭代次数Epoch: 4100 下降值cost= 0.077167228 W= 0.254368 b= 0.802655\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076932222 W= 0.250815 b= 0.802143\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076953657 W= 0.250142 b= 0.801981\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076932319 W= 0.25082 b= 0.80205\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076936200 W= 0.251705 b= 0.802194\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076931290 W= 0.25089 b= 0.802086\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076934002 W= 0.250731 b= 0.802013\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076938711 W= 0.251805 b= 0.802165\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076931432 W= 0.25146 b= 0.802133\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076965265 W= 0.249934 b= 0.801846\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076942809 W= 0.250421 b= 0.801907\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076929636 W= 0.251094 b= 0.802026\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076958105 W= 0.250059 b= 0.801915\n",
      "迭代次数Epoch: 4100 下降值cost= 0.076990843 W= 0.249554 b= 0.801751\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076980174 W= 0.249701 b= 0.801781\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076943107 W= 0.251926 b= 0.802286\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076934181 W= 0.251609 b= 0.802229\n",
      "迭代次数Epoch: 4150 下降值cost= 0.077167243 W= 0.25437 b= 0.80264\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076932207 W= 0.250818 b= 0.802128\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076953657 W= 0.250145 b= 0.801966\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076932333 W= 0.250823 b= 0.802036\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076936193 W= 0.251708 b= 0.802179\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076931283 W= 0.250892 b= 0.802071\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076934002 W= 0.250733 b= 0.801998\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076938719 W= 0.251807 b= 0.80215\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076931417 W= 0.251462 b= 0.802118\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076965235 W= 0.249937 b= 0.801831\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076942801 W= 0.250423 b= 0.801892\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076929636 W= 0.251096 b= 0.802011\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076958098 W= 0.250061 b= 0.8019\n",
      "迭代次数Epoch: 4150 下降值cost= 0.076990828 W= 0.249556 b= 0.801737\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076980181 W= 0.249703 b= 0.801768\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076943099 W= 0.251927 b= 0.802274\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076934159 W= 0.251611 b= 0.802217\n",
      "迭代次数Epoch: 4200 下降值cost= 0.077167235 W= 0.254372 b= 0.802628\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076932214 W= 0.250819 b= 0.802115\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076953635 W= 0.250146 b= 0.801954\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076932319 W= 0.250824 b= 0.802023\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076936185 W= 0.251709 b= 0.802166\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076931268 W= 0.250894 b= 0.802059\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076933987 W= 0.250735 b= 0.801986\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076938704 W= 0.251809 b= 0.802138\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076931417 W= 0.251464 b= 0.802106\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076965250 W= 0.249938 b= 0.801819\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076942794 W= 0.250425 b= 0.80188\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076929644 W= 0.251097 b= 0.801999\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076958105 W= 0.250063 b= 0.801887\n",
      "迭代次数Epoch: 4200 下降值cost= 0.076990828 W= 0.249558 b= 0.801724\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076980181 W= 0.249704 b= 0.801759\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076943092 W= 0.251929 b= 0.802264\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076934181 W= 0.251612 b= 0.802207\n",
      "迭代次数Epoch: 4250 下降值cost= 0.077167220 W= 0.254373 b= 0.802618\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076932222 W= 0.250821 b= 0.802106\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076953627 W= 0.250148 b= 0.801944\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076932311 W= 0.250826 b= 0.802014\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076936185 W= 0.251711 b= 0.802157\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076931261 W= 0.250895 b= 0.802049\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076933980 W= 0.250736 b= 0.801976\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076938689 W= 0.25181 b= 0.802128\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076931417 W= 0.251465 b= 0.802096\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076965243 W= 0.24994 b= 0.801809\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076942801 W= 0.250426 b= 0.80187\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076929644 W= 0.251099 b= 0.801989\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076958098 W= 0.250064 b= 0.801878\n",
      "迭代次数Epoch: 4250 下降值cost= 0.076990820 W= 0.249559 b= 0.801715\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076980174 W= 0.249705 b= 0.80175\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076943099 W= 0.25193 b= 0.802256\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076934166 W= 0.251614 b= 0.802198\n",
      "迭代次数Epoch: 4300 下降值cost= 0.077167228 W= 0.254374 b= 0.802609\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076932222 W= 0.250822 b= 0.802097\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076953612 W= 0.250149 b= 0.801935\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076932296 W= 0.250827 b= 0.802005\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076936170 W= 0.251712 b= 0.802148\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076931253 W= 0.250897 b= 0.80204\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076933973 W= 0.250738 b= 0.801967\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076938689 W= 0.251812 b= 0.80212\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076931417 W= 0.251466 b= 0.802088\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076965235 W= 0.249941 b= 0.8018\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076942772 W= 0.250427 b= 0.801861\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076929629 W= 0.2511 b= 0.80198\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076958105 W= 0.250066 b= 0.801869\n",
      "迭代次数Epoch: 4300 下降值cost= 0.076990783 W= 0.24956 b= 0.801706\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076980174 W= 0.249707 b= 0.801741\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076943085 W= 0.251931 b= 0.802247\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076934159 W= 0.251615 b= 0.802189\n",
      "迭代次数Epoch: 4350 下降值cost= 0.077167220 W= 0.254376 b= 0.8026\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076932214 W= 0.250823 b= 0.802088\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076953627 W= 0.25015 b= 0.801926\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076932281 W= 0.250828 b= 0.801996\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076936185 W= 0.251713 b= 0.802139\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076931253 W= 0.250898 b= 0.802031\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076933980 W= 0.250739 b= 0.801958\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076938689 W= 0.251813 b= 0.802111\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076931410 W= 0.251468 b= 0.802079\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076965228 W= 0.249942 b= 0.801791\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076942787 W= 0.250429 b= 0.801852\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076929636 W= 0.251101 b= 0.801971\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076958098 W= 0.250067 b= 0.80186\n",
      "迭代次数Epoch: 4350 下降值cost= 0.076990820 W= 0.249562 b= 0.801697\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076980174 W= 0.249708 b= 0.801732\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076943070 W= 0.251933 b= 0.802238\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076934151 W= 0.251616 b= 0.80218\n",
      "迭代次数Epoch: 4400 下降值cost= 0.077167243 W= 0.254377 b= 0.802592\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076932199 W= 0.250825 b= 0.802079\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076953620 W= 0.250152 b= 0.801917\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076932289 W= 0.250829 b= 0.801987\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076936178 W= 0.251715 b= 0.80213\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076931261 W= 0.250899 b= 0.802023\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076933973 W= 0.25074 b= 0.801949\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076938689 W= 0.251814 b= 0.802102\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076931395 W= 0.251469 b= 0.80207\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076965220 W= 0.249943 b= 0.801783\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076942794 W= 0.25043 b= 0.801843\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076929636 W= 0.251102 b= 0.801962\n",
      "迭代次数Epoch: 4400 下降值cost= 0.076958090 W= 0.250068 b= 0.801851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 4400 下降值cost= 0.076990806 W= 0.249563 b= 0.801688\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076980166 W= 0.24971 b= 0.80172\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076943077 W= 0.251934 b= 0.802226\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076934151 W= 0.251618 b= 0.802168\n",
      "迭代次数Epoch: 4450 下降值cost= 0.077167228 W= 0.254379 b= 0.80258\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076932207 W= 0.250826 b= 0.802067\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076953605 W= 0.250153 b= 0.801906\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076932274 W= 0.250831 b= 0.801975\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076936163 W= 0.251716 b= 0.802118\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076931261 W= 0.250901 b= 0.802011\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076933980 W= 0.250742 b= 0.801937\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076938681 W= 0.251816 b= 0.80209\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076931410 W= 0.251471 b= 0.802058\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076965235 W= 0.249945 b= 0.801771\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076942772 W= 0.250431 b= 0.801832\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076929614 W= 0.251104 b= 0.801951\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076958075 W= 0.25007 b= 0.801839\n",
      "迭代次数Epoch: 4450 下降值cost= 0.076990806 W= 0.249564 b= 0.801676\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076980166 W= 0.249711 b= 0.801708\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076943077 W= 0.251936 b= 0.802214\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076934151 W= 0.251619 b= 0.802156\n",
      "迭代次数Epoch: 4500 下降值cost= 0.077167213 W= 0.25438 b= 0.802568\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076932199 W= 0.250828 b= 0.802055\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076953605 W= 0.250155 b= 0.801894\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076932289 W= 0.250833 b= 0.801963\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076936170 W= 0.251718 b= 0.802106\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076931246 W= 0.250902 b= 0.801999\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076933958 W= 0.250743 b= 0.801925\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076938674 W= 0.251818 b= 0.802078\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076931402 W= 0.251472 b= 0.802046\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076965235 W= 0.249947 b= 0.801759\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076942772 W= 0.250433 b= 0.80182\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076929629 W= 0.251106 b= 0.801939\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076958075 W= 0.250071 b= 0.801827\n",
      "迭代次数Epoch: 4500 下降值cost= 0.076990798 W= 0.249566 b= 0.801664\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076980159 W= 0.249713 b= 0.801696\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076943077 W= 0.251938 b= 0.802202\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076934136 W= 0.251621 b= 0.802144\n",
      "迭代次数Epoch: 4550 下降值cost= 0.077167213 W= 0.254382 b= 0.802556\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076932184 W= 0.25083 b= 0.802043\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076953597 W= 0.250157 b= 0.801882\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076932281 W= 0.250834 b= 0.801951\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076936170 W= 0.25172 b= 0.802094\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076931238 W= 0.250904 b= 0.801987\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076933965 W= 0.250745 b= 0.801913\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076938681 W= 0.251819 b= 0.802066\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076931402 W= 0.251474 b= 0.802034\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076965213 W= 0.249948 b= 0.801747\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076942772 W= 0.250435 b= 0.801808\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076929621 W= 0.251107 b= 0.801927\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076958083 W= 0.250073 b= 0.801815\n",
      "迭代次数Epoch: 4550 下降值cost= 0.076990798 W= 0.249568 b= 0.801652\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076980166 W= 0.249715 b= 0.801684\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076943062 W= 0.251939 b= 0.80219\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076934136 W= 0.251623 b= 0.802133\n",
      "迭代次数Epoch: 4600 下降值cost= 0.077167228 W= 0.254384 b= 0.802544\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076932177 W= 0.250831 b= 0.802031\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076953605 W= 0.250158 b= 0.80187\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076932274 W= 0.250836 b= 0.801939\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076936148 W= 0.251721 b= 0.802082\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076931231 W= 0.250906 b= 0.801975\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076933958 W= 0.250747 b= 0.801902\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076938674 W= 0.251821 b= 0.802054\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076931387 W= 0.251475 b= 0.802022\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076965190 W= 0.24995 b= 0.801735\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076942764 W= 0.250436 b= 0.801796\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076929629 W= 0.251109 b= 0.801915\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076958068 W= 0.250075 b= 0.801803\n",
      "迭代次数Epoch: 4600 下降值cost= 0.076990798 W= 0.249569 b= 0.80164\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076980151 W= 0.249716 b= 0.801674\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076943047 W= 0.251941 b= 0.80218\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076934136 W= 0.251624 b= 0.802122\n",
      "迭代次数Epoch: 4650 下降值cost= 0.077167220 W= 0.254385 b= 0.802534\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076932169 W= 0.250833 b= 0.802021\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076953590 W= 0.25016 b= 0.80186\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076932251 W= 0.250838 b= 0.801929\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076936133 W= 0.251723 b= 0.802072\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076931253 W= 0.250907 b= 0.801965\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076933950 W= 0.250748 b= 0.801891\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076938681 W= 0.251823 b= 0.802044\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076931387 W= 0.251477 b= 0.802012\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076965205 W= 0.249951 b= 0.801725\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076942757 W= 0.250438 b= 0.801786\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076929606 W= 0.25111 b= 0.801905\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076958060 W= 0.250076 b= 0.801793\n",
      "迭代次数Epoch: 4650 下降值cost= 0.076990798 W= 0.249571 b= 0.80163\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076980151 W= 0.249717 b= 0.801664\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076943040 W= 0.251942 b= 0.80217\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076934144 W= 0.251626 b= 0.802112\n",
      "迭代次数Epoch: 4700 下降值cost= 0.077167191 W= 0.254386 b= 0.802523\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076932177 W= 0.250834 b= 0.802011\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076953590 W= 0.250161 b= 0.801849\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076932274 W= 0.250839 b= 0.801919\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076936118 W= 0.251724 b= 0.802062\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076931231 W= 0.250909 b= 0.801954\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076933958 W= 0.25075 b= 0.801881\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076938666 W= 0.251824 b= 0.802034\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076931387 W= 0.251478 b= 0.802002\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076965213 W= 0.249953 b= 0.801714\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076942764 W= 0.250439 b= 0.801775\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076929592 W= 0.251112 b= 0.801894\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076958068 W= 0.250077 b= 0.801783\n",
      "迭代次数Epoch: 4700 下降值cost= 0.076990806 W= 0.249572 b= 0.80162\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076980144 W= 0.249719 b= 0.801652\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076943055 W= 0.251944 b= 0.802158\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076934136 W= 0.251627 b= 0.8021\n",
      "迭代次数Epoch: 4750 下降值cost= 0.077167213 W= 0.254388 b= 0.802512\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076932169 W= 0.250836 b= 0.801999\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076953582 W= 0.250163 b= 0.801838\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076932259 W= 0.250841 b= 0.801907\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076936118 W= 0.251726 b= 0.80205\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076931201 W= 0.25091 b= 0.801943\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076933928 W= 0.250751 b= 0.801869\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076938681 W= 0.251826 b= 0.802022\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076931387 W= 0.25148 b= 0.80199\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076965198 W= 0.249955 b= 0.801703\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076942764 W= 0.250441 b= 0.801763\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076929592 W= 0.251114 b= 0.801882\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076958075 W= 0.250079 b= 0.801771\n",
      "迭代次数Epoch: 4750 下降值cost= 0.076990783 W= 0.249574 b= 0.801608\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076980166 W= 0.249721 b= 0.80164\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076943040 W= 0.251945 b= 0.802146\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076934122 W= 0.251629 b= 0.802088\n",
      "迭代次数Epoch: 4800 下降值cost= 0.077167183 W= 0.25439 b= 0.8025\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076932169 W= 0.250837 b= 0.801987\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076953582 W= 0.250165 b= 0.801826\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076932251 W= 0.250842 b= 0.801895\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076936133 W= 0.251727 b= 0.802038\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076931223 W= 0.250912 b= 0.801931\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076933943 W= 0.250753 b= 0.801857\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076938659 W= 0.251827 b= 0.80201\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076931380 W= 0.251481 b= 0.801978\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076965205 W= 0.249956 b= 0.801691\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076942757 W= 0.250442 b= 0.801751\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076929577 W= 0.251115 b= 0.80187\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076958075 W= 0.250081 b= 0.801759\n",
      "迭代次数Epoch: 4800 下降值cost= 0.076990783 W= 0.249575 b= 0.801596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 4850 下降值cost= 0.076980136 W= 0.249722 b= 0.801628\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076943040 W= 0.251947 b= 0.802134\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076934129 W= 0.251631 b= 0.802076\n",
      "迭代次数Epoch: 4850 下降值cost= 0.077167191 W= 0.254392 b= 0.802488\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076932155 W= 0.250839 b= 0.801975\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076953575 W= 0.250166 b= 0.801814\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076932259 W= 0.250844 b= 0.801883\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076936118 W= 0.251729 b= 0.802026\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076931208 W= 0.250914 b= 0.801919\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076933928 W= 0.250755 b= 0.801845\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076938666 W= 0.251829 b= 0.801998\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076931380 W= 0.251483 b= 0.801966\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076965205 W= 0.249958 b= 0.801679\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076942742 W= 0.250444 b= 0.80174\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076929614 W= 0.251117 b= 0.801859\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076958053 W= 0.250082 b= 0.801747\n",
      "迭代次数Epoch: 4850 下降值cost= 0.076990791 W= 0.249577 b= 0.801584\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076980136 W= 0.249724 b= 0.801616\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076943040 W= 0.251949 b= 0.802122\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076934114 W= 0.251632 b= 0.802064\n",
      "迭代次数Epoch: 4900 下降值cost= 0.077167183 W= 0.254393 b= 0.802476\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076932162 W= 0.250841 b= 0.801963\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076953575 W= 0.250168 b= 0.801802\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076932251 W= 0.250846 b= 0.801871\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076936118 W= 0.251731 b= 0.802014\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076931201 W= 0.250915 b= 0.801907\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076933935 W= 0.250756 b= 0.801833\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076938644 W= 0.251831 b= 0.801986\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076931357 W= 0.251485 b= 0.801954\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076965198 W= 0.249959 b= 0.801667\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076942749 W= 0.250446 b= 0.801728\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076929584 W= 0.251119 b= 0.801847\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076958060 W= 0.250084 b= 0.801735\n",
      "迭代次数Epoch: 4900 下降值cost= 0.076990783 W= 0.249579 b= 0.801572\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076980144 W= 0.249726 b= 0.801604\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076943025 W= 0.251951 b= 0.80211\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076934107 W= 0.251634 b= 0.802052\n",
      "迭代次数Epoch: 4950 下降值cost= 0.077167183 W= 0.254395 b= 0.802464\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076932155 W= 0.250843 b= 0.801951\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076953560 W= 0.25017 b= 0.80179\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076932251 W= 0.250847 b= 0.801859\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076936126 W= 0.251732 b= 0.802002\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076931216 W= 0.250917 b= 0.801895\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076933920 W= 0.250758 b= 0.801822\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076938644 W= 0.251832 b= 0.801974\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076931357 W= 0.251486 b= 0.801942\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076965183 W= 0.249961 b= 0.801655\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076942757 W= 0.250447 b= 0.801716\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076929584 W= 0.25112 b= 0.801835\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076958038 W= 0.250086 b= 0.801723\n",
      "迭代次数Epoch: 4950 下降值cost= 0.076990798 W= 0.249581 b= 0.80156\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076980136 W= 0.249727 b= 0.801592\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076943018 W= 0.251952 b= 0.802098\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076934092 W= 0.251636 b= 0.80204\n",
      "迭代次数Epoch: 5000 下降值cost= 0.077167176 W= 0.254397 b= 0.802452\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076932147 W= 0.250844 b= 0.801939\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076953568 W= 0.250171 b= 0.801778\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076932251 W= 0.250849 b= 0.801847\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076936111 W= 0.251734 b= 0.80199\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076931193 W= 0.250919 b= 0.801883\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076933920 W= 0.25076 b= 0.801809\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076938622 W= 0.251834 b= 0.801962\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076931350 W= 0.251488 b= 0.80193\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076965190 W= 0.249963 b= 0.801643\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076942742 W= 0.250449 b= 0.801704\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076929569 W= 0.251122 b= 0.801823\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076958053 W= 0.250087 b= 0.801711\n",
      "迭代次数Epoch: 5000 下降值cost= 0.076990783 W= 0.249582 b= 0.801548\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076980136 W= 0.249729 b= 0.801581\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076943010 W= 0.251954 b= 0.802086\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076934099 W= 0.251637 b= 0.802029\n",
      "迭代次数Epoch: 5050 下降值cost= 0.077167191 W= 0.254398 b= 0.80244\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076932147 W= 0.250846 b= 0.801927\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076953560 W= 0.250173 b= 0.801766\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076932244 W= 0.250851 b= 0.801835\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076936096 W= 0.251736 b= 0.801978\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076931186 W= 0.25092 b= 0.801871\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076933928 W= 0.250762 b= 0.801798\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076938622 W= 0.251836 b= 0.80195\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076931342 W= 0.25149 b= 0.801918\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076965190 W= 0.249964 b= 0.801631\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076942742 W= 0.250451 b= 0.801692\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076929569 W= 0.251124 b= 0.801811\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076958038 W= 0.250089 b= 0.801699\n",
      "迭代次数Epoch: 5050 下降值cost= 0.076990783 W= 0.249584 b= 0.801536\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076980121 W= 0.249731 b= 0.80157\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076943018 W= 0.251955 b= 0.802076\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076934114 W= 0.251639 b= 0.802019\n",
      "迭代次数Epoch: 5100 下降值cost= 0.077167198 W= 0.2544 b= 0.80243\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076932140 W= 0.250848 b= 0.801917\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076953538 W= 0.250175 b= 0.801756\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076932244 W= 0.250852 b= 0.801825\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076936118 W= 0.251737 b= 0.801968\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076931193 W= 0.250922 b= 0.801861\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076933920 W= 0.250763 b= 0.801788\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076938629 W= 0.251837 b= 0.80194\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076931342 W= 0.251491 b= 0.801908\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076965183 W= 0.249966 b= 0.801621\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076942742 W= 0.250452 b= 0.801682\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076929569 W= 0.251125 b= 0.801801\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076958053 W= 0.25009 b= 0.801689\n",
      "迭代次数Epoch: 5100 下降值cost= 0.076990783 W= 0.249585 b= 0.801526\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076980129 W= 0.249731 b= 0.801564\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076943018 W= 0.251956 b= 0.80207\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076934084 W= 0.25164 b= 0.802013\n",
      "迭代次数Epoch: 5150 下降值cost= 0.077167176 W= 0.254401 b= 0.802424\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076932132 W= 0.250848 b= 0.801911\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076953530 W= 0.250176 b= 0.80175\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076932244 W= 0.250853 b= 0.801819\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076936103 W= 0.251738 b= 0.801962\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076931193 W= 0.250923 b= 0.801855\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076933913 W= 0.250764 b= 0.801782\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076938622 W= 0.251838 b= 0.801934\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076931335 W= 0.251492 b= 0.801902\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076965168 W= 0.249967 b= 0.801615\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076942742 W= 0.250453 b= 0.801676\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076929562 W= 0.251126 b= 0.801795\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076958045 W= 0.250091 b= 0.801683\n",
      "迭代次数Epoch: 5150 下降值cost= 0.076990783 W= 0.249586 b= 0.80152\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076980114 W= 0.249732 b= 0.80156\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076943018 W= 0.251957 b= 0.802065\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076934099 W= 0.251641 b= 0.802008\n",
      "迭代次数Epoch: 5200 下降值cost= 0.077167198 W= 0.254401 b= 0.802419\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076932132 W= 0.250849 b= 0.801907\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076953530 W= 0.250176 b= 0.801745\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076932237 W= 0.250854 b= 0.801815\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076936103 W= 0.251739 b= 0.801958\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076931186 W= 0.250923 b= 0.80185\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076933898 W= 0.250765 b= 0.801777\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076938622 W= 0.251839 b= 0.80193\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076931342 W= 0.251493 b= 0.801897\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076965190 W= 0.249967 b= 0.80161\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076942734 W= 0.250454 b= 0.801671\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076929577 W= 0.251126 b= 0.80179\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076958053 W= 0.250092 b= 0.801679\n",
      "迭代次数Epoch: 5200 下降值cost= 0.076990768 W= 0.249587 b= 0.801516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 5250 下降值cost= 0.076980107 W= 0.249733 b= 0.801557\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076943010 W= 0.251957 b= 0.802062\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076934107 W= 0.251641 b= 0.802005\n",
      "迭代次数Epoch: 5250 下降值cost= 0.077167198 W= 0.254402 b= 0.802416\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076932132 W= 0.25085 b= 0.801904\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076953530 W= 0.250177 b= 0.801742\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076932244 W= 0.250854 b= 0.801812\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076936118 W= 0.251739 b= 0.801955\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076931186 W= 0.250924 b= 0.801847\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076933891 W= 0.250765 b= 0.801774\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076938622 W= 0.251839 b= 0.801927\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076931320 W= 0.251493 b= 0.801894\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076965176 W= 0.249968 b= 0.801607\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076942742 W= 0.250454 b= 0.801668\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076929562 W= 0.251127 b= 0.801787\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076958038 W= 0.250092 b= 0.801676\n",
      "迭代次数Epoch: 5250 下降值cost= 0.076990768 W= 0.249587 b= 0.801513\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076980129 W= 0.249733 b= 0.801554\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076943003 W= 0.251958 b= 0.802059\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076934107 W= 0.251641 b= 0.802002\n",
      "迭代次数Epoch: 5300 下降值cost= 0.077167191 W= 0.254402 b= 0.802413\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076932132 W= 0.25085 b= 0.801901\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076953530 W= 0.250177 b= 0.801739\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076932237 W= 0.250854 b= 0.801809\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076936111 W= 0.25174 b= 0.801952\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076931186 W= 0.250924 b= 0.801844\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076933898 W= 0.250765 b= 0.801771\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076938614 W= 0.25184 b= 0.801924\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076931335 W= 0.251494 b= 0.801892\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076965183 W= 0.249968 b= 0.801604\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076942742 W= 0.250455 b= 0.801665\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076929577 W= 0.251127 b= 0.801784\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076958038 W= 0.250093 b= 0.801673\n",
      "迭代次数Epoch: 5300 下降值cost= 0.076990768 W= 0.249588 b= 0.80151\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076980129 W= 0.249733 b= 0.801551\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076942988 W= 0.251958 b= 0.802056\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076934069 W= 0.251642 b= 0.801999\n",
      "迭代次数Epoch: 5350 下降值cost= 0.077167153 W= 0.254403 b= 0.80241\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076932125 W= 0.25085 b= 0.801898\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076953538 W= 0.250177 b= 0.801736\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076932222 W= 0.250855 b= 0.801806\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076936089 W= 0.25174 b= 0.801949\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076931171 W= 0.250924 b= 0.801841\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076933920 W= 0.250766 b= 0.801768\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076938622 W= 0.25184 b= 0.801921\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076931328 W= 0.251494 b= 0.801889\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076965176 W= 0.249968 b= 0.801601\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076942742 W= 0.250455 b= 0.801662\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076929569 W= 0.251128 b= 0.801781\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076958053 W= 0.250093 b= 0.80167\n",
      "迭代次数Epoch: 5350 下降值cost= 0.076990776 W= 0.249588 b= 0.801507\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076980114 W= 0.249734 b= 0.801548\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076942980 W= 0.251959 b= 0.802054\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076934084 W= 0.251642 b= 0.801996\n",
      "迭代次数Epoch: 5400 下降值cost= 0.077167183 W= 0.254403 b= 0.802407\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076932132 W= 0.250851 b= 0.801895\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076953538 W= 0.250178 b= 0.801733\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076932214 W= 0.250855 b= 0.801803\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076936096 W= 0.251741 b= 0.801946\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076931179 W= 0.250925 b= 0.801838\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076933913 W= 0.250766 b= 0.801765\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076938629 W= 0.251841 b= 0.801918\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076931328 W= 0.251494 b= 0.801886\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076965176 W= 0.249969 b= 0.801598\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076942734 W= 0.250455 b= 0.801659\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076929547 W= 0.251128 b= 0.801778\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076958030 W= 0.250093 b= 0.801667\n",
      "迭代次数Epoch: 5400 下降值cost= 0.076990761 W= 0.249588 b= 0.801504\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076980099 W= 0.249735 b= 0.801543\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076943010 W= 0.251959 b= 0.802049\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076934084 W= 0.251643 b= 0.801991\n",
      "迭代次数Epoch: 5450 下降值cost= 0.077167183 W= 0.254404 b= 0.802403\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076932125 W= 0.250852 b= 0.80189\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076953508 W= 0.250179 b= 0.801729\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076932207 W= 0.250856 b= 0.801798\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076936089 W= 0.251741 b= 0.801941\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076931171 W= 0.250926 b= 0.801834\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076933891 W= 0.250767 b= 0.80176\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076938614 W= 0.251841 b= 0.801913\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076931335 W= 0.251495 b= 0.801881\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076965153 W= 0.24997 b= 0.801594\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076942742 W= 0.250456 b= 0.801654\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076929547 W= 0.251129 b= 0.801773\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076958038 W= 0.250094 b= 0.801662\n",
      "迭代次数Epoch: 5450 下降值cost= 0.076990761 W= 0.249589 b= 0.801499\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076980121 W= 0.249735 b= 0.801537\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076942988 W= 0.25196 b= 0.802043\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076934077 W= 0.251644 b= 0.801985\n",
      "迭代次数Epoch: 5500 下降值cost= 0.077167176 W= 0.254405 b= 0.802397\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076932125 W= 0.250852 b= 0.801884\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076953530 W= 0.250179 b= 0.801723\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076932222 W= 0.250857 b= 0.801792\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076936081 W= 0.251742 b= 0.801935\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076931186 W= 0.250926 b= 0.801828\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076933905 W= 0.250768 b= 0.801754\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076938607 W= 0.251842 b= 0.801907\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076931320 W= 0.251496 b= 0.801875\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076965190 W= 0.24997 b= 0.801588\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076942734 W= 0.250457 b= 0.801648\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076929562 W= 0.25113 b= 0.801767\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076958038 W= 0.250095 b= 0.801656\n",
      "迭代次数Epoch: 5500 下降值cost= 0.076990768 W= 0.24959 b= 0.801493\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076980107 W= 0.249736 b= 0.801532\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076942995 W= 0.251961 b= 0.802038\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076934084 W= 0.251644 b= 0.80198\n",
      "迭代次数Epoch: 5550 下降值cost= 0.077167176 W= 0.254405 b= 0.802392\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076932132 W= 0.250853 b= 0.801879\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076953538 W= 0.25018 b= 0.801718\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076932222 W= 0.250858 b= 0.801787\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076936081 W= 0.251743 b= 0.80193\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076931171 W= 0.250927 b= 0.801823\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076933905 W= 0.250768 b= 0.801749\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076938622 W= 0.251843 b= 0.801902\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076931335 W= 0.251497 b= 0.80187\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076965168 W= 0.249971 b= 0.801583\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076942720 W= 0.250458 b= 0.801643\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076929562 W= 0.25113 b= 0.801762\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076958038 W= 0.250096 b= 0.801651\n",
      "迭代次数Epoch: 5550 下降值cost= 0.076990768 W= 0.249591 b= 0.801488\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076980114 W= 0.249736 b= 0.801529\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076942988 W= 0.251961 b= 0.802035\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076934084 W= 0.251645 b= 0.801977\n",
      "迭代次数Epoch: 5600 下降值cost= 0.077167183 W= 0.254406 b= 0.802389\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076932125 W= 0.250853 b= 0.801876\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076953515 W= 0.250181 b= 0.801715\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076932214 W= 0.250858 b= 0.801784\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076936089 W= 0.251743 b= 0.801927\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076931179 W= 0.250928 b= 0.80182\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076933898 W= 0.250769 b= 0.801746\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076938607 W= 0.251843 b= 0.801899\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076931320 W= 0.251497 b= 0.801867\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076965176 W= 0.249972 b= 0.80158\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076942734 W= 0.250458 b= 0.801641\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076929569 W= 0.251131 b= 0.801759\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076958038 W= 0.250096 b= 0.801648\n",
      "迭代次数Epoch: 5600 下降值cost= 0.076990776 W= 0.249591 b= 0.801485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 5650 下降值cost= 0.076980107 W= 0.249737 b= 0.801526\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076942995 W= 0.251962 b= 0.802032\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076934092 W= 0.251645 b= 0.801974\n",
      "迭代次数Epoch: 5650 下降值cost= 0.077167168 W= 0.254406 b= 0.802386\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076932117 W= 0.250854 b= 0.801873\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076953530 W= 0.250181 b= 0.801712\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076932222 W= 0.250858 b= 0.801781\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076936096 W= 0.251744 b= 0.801924\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076931179 W= 0.250928 b= 0.801817\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076933905 W= 0.250769 b= 0.801743\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076938622 W= 0.251844 b= 0.801896\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076931320 W= 0.251497 b= 0.801864\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076965153 W= 0.249972 b= 0.801577\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076942727 W= 0.250458 b= 0.801638\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076929554 W= 0.251131 b= 0.801757\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076958038 W= 0.250096 b= 0.801645\n",
      "迭代次数Epoch: 5650 下降值cost= 0.076990783 W= 0.249591 b= 0.801482\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076980114 W= 0.249737 b= 0.801523\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076942988 W= 0.251962 b= 0.802029\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076934092 W= 0.251646 b= 0.801971\n",
      "迭代次数Epoch: 5700 下降值cost= 0.077167146 W= 0.254406 b= 0.802383\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076932117 W= 0.250854 b= 0.80187\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076953538 W= 0.250181 b= 0.801709\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076932237 W= 0.250859 b= 0.801778\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076936089 W= 0.251744 b= 0.801921\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076931164 W= 0.250928 b= 0.801814\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076933905 W= 0.25077 b= 0.80174\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076938614 W= 0.251844 b= 0.801893\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076931328 W= 0.251498 b= 0.801861\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076965183 W= 0.249972 b= 0.801574\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076942734 W= 0.250459 b= 0.801635\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076929554 W= 0.251131 b= 0.801754\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076958038 W= 0.250097 b= 0.801642\n",
      "迭代次数Epoch: 5700 下降值cost= 0.076990783 W= 0.249592 b= 0.801479\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076980129 W= 0.249738 b= 0.80152\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076942973 W= 0.251962 b= 0.802026\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076934069 W= 0.251646 b= 0.801968\n",
      "迭代次数Epoch: 5750 下降值cost= 0.077167168 W= 0.254407 b= 0.80238\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076932125 W= 0.250855 b= 0.801867\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076953530 W= 0.250182 b= 0.801706\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076932207 W= 0.250859 b= 0.801775\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076936074 W= 0.251744 b= 0.801918\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076931164 W= 0.250929 b= 0.801811\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076933883 W= 0.25077 b= 0.801737\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076938599 W= 0.251844 b= 0.80189\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076931313 W= 0.251498 b= 0.801858\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076965161 W= 0.249973 b= 0.801571\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076942720 W= 0.250459 b= 0.801632\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076929539 W= 0.251132 b= 0.801751\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076958038 W= 0.250097 b= 0.801639\n",
      "迭代次数Epoch: 5750 下降值cost= 0.076990768 W= 0.249592 b= 0.801476\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076980114 W= 0.249738 b= 0.801517\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076942995 W= 0.251963 b= 0.802023\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076934069 W= 0.251646 b= 0.801965\n",
      "迭代次数Epoch: 5800 下降值cost= 0.077167168 W= 0.254407 b= 0.802377\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076932132 W= 0.250855 b= 0.801864\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076953523 W= 0.250182 b= 0.801703\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076932199 W= 0.25086 b= 0.801772\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076936081 W= 0.251745 b= 0.801915\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076931179 W= 0.250929 b= 0.801808\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076933891 W= 0.25077 b= 0.801734\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076938614 W= 0.251845 b= 0.801887\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076931320 W= 0.251499 b= 0.801855\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076965176 W= 0.249973 b= 0.801568\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076942720 W= 0.25046 b= 0.801629\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076929547 W= 0.251132 b= 0.801748\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076958045 W= 0.250098 b= 0.801636\n",
      "迭代次数Epoch: 5800 下降值cost= 0.076990753 W= 0.249593 b= 0.801473\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076980092 W= 0.249738 b= 0.801514\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076943003 W= 0.251963 b= 0.80202\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076934062 W= 0.251647 b= 0.801962\n",
      "迭代次数Epoch: 5850 下降值cost= 0.077167161 W= 0.254408 b= 0.802374\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076932125 W= 0.250855 b= 0.801861\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076953515 W= 0.250183 b= 0.8017\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076932207 W= 0.25086 b= 0.801769\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076936089 W= 0.251745 b= 0.801912\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076931164 W= 0.25093 b= 0.801805\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076933891 W= 0.250771 b= 0.801731\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076938607 W= 0.251845 b= 0.801884\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076931305 W= 0.251499 b= 0.801852\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076965176 W= 0.249974 b= 0.801565\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076942712 W= 0.25046 b= 0.801626\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076929554 W= 0.251133 b= 0.801745\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076958038 W= 0.250098 b= 0.801633\n",
      "迭代次数Epoch: 5850 下降值cost= 0.076990768 W= 0.249593 b= 0.80147\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076980121 W= 0.249739 b= 0.801511\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076942980 W= 0.251964 b= 0.802017\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076934069 W= 0.251647 b= 0.801959\n",
      "迭代次数Epoch: 5900 下降值cost= 0.077167153 W= 0.254408 b= 0.802371\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076932102 W= 0.250856 b= 0.801858\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076953515 W= 0.250183 b= 0.801697\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076932229 W= 0.25086 b= 0.801766\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076936059 W= 0.251746 b= 0.801909\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076931179 W= 0.25093 b= 0.801802\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076933891 W= 0.250771 b= 0.801728\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076938614 W= 0.251846 b= 0.801881\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076931305 W= 0.251499 b= 0.801849\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076965161 W= 0.249974 b= 0.801562\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076942742 W= 0.25046 b= 0.801623\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076929547 W= 0.251133 b= 0.801742\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076958053 W= 0.250098 b= 0.80163\n",
      "迭代次数Epoch: 5900 下降值cost= 0.076990776 W= 0.249593 b= 0.801467\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076980107 W= 0.249739 b= 0.801508\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076943010 W= 0.251964 b= 0.802014\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076934047 W= 0.251648 b= 0.801956\n",
      "迭代次数Epoch: 5950 下降值cost= 0.077167161 W= 0.254409 b= 0.802368\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076932117 W= 0.250856 b= 0.801855\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076953515 W= 0.250183 b= 0.801694\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076932207 W= 0.250861 b= 0.801763\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076936096 W= 0.251746 b= 0.801906\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076931179 W= 0.250931 b= 0.801799\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076933883 W= 0.250772 b= 0.801726\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076938614 W= 0.251846 b= 0.801878\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076931305 W= 0.2515 b= 0.801846\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076965153 W= 0.249974 b= 0.801559\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076942720 W= 0.250461 b= 0.80162\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076929547 W= 0.251134 b= 0.801739\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076958023 W= 0.250099 b= 0.801627\n",
      "迭代次数Epoch: 5950 下降值cost= 0.076990768 W= 0.249594 b= 0.801464\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076980099 W= 0.24974 b= 0.801505\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076942980 W= 0.251965 b= 0.802011\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076934069 W= 0.251648 b= 0.801953\n",
      "迭代次数Epoch: 6000 下降值cost= 0.077167124 W= 0.254409 b= 0.802365\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076932117 W= 0.250857 b= 0.801852\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076953530 W= 0.250184 b= 0.801691\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076932214 W= 0.250861 b= 0.80176\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076936074 W= 0.251746 b= 0.801903\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076931164 W= 0.250931 b= 0.801796\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076933905 W= 0.250772 b= 0.801723\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076938599 W= 0.251846 b= 0.801875\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076931298 W= 0.2515 b= 0.801843\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076965161 W= 0.249975 b= 0.801556\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076942720 W= 0.250461 b= 0.801617\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076929539 W= 0.251134 b= 0.801736\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076958038 W= 0.250099 b= 0.801624\n",
      "迭代次数Epoch: 6000 下降值cost= 0.076990776 W= 0.249594 b= 0.801461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 6050 下降值cost= 0.076980099 W= 0.24974 b= 0.801502\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076942980 W= 0.251965 b= 0.802008\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076934069 W= 0.251649 b= 0.80195\n",
      "迭代次数Epoch: 6050 下降值cost= 0.077167153 W= 0.254409 b= 0.802362\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076932125 W= 0.250857 b= 0.801849\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076953508 W= 0.250184 b= 0.801688\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076932199 W= 0.250862 b= 0.801757\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076936074 W= 0.251747 b= 0.8019\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076931171 W= 0.250931 b= 0.801793\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076933891 W= 0.250773 b= 0.80172\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076938599 W= 0.251847 b= 0.801872\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076931305 W= 0.251501 b= 0.80184\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076965153 W= 0.249975 b= 0.801553\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076942734 W= 0.250462 b= 0.801614\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076929547 W= 0.251134 b= 0.801733\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076958023 W= 0.2501 b= 0.801621\n",
      "迭代次数Epoch: 6050 下降值cost= 0.076990761 W= 0.249595 b= 0.801458\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076980121 W= 0.24974 b= 0.801499\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076942988 W= 0.251965 b= 0.802005\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076934069 W= 0.251649 b= 0.801947\n",
      "迭代次数Epoch: 6100 下降值cost= 0.077167161 W= 0.25441 b= 0.802359\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076932117 W= 0.250858 b= 0.801846\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076953523 W= 0.250185 b= 0.801685\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076932199 W= 0.250862 b= 0.801754\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076936066 W= 0.251747 b= 0.801897\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076931164 W= 0.250932 b= 0.80179\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076933891 W= 0.250773 b= 0.801717\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076938592 W= 0.251847 b= 0.801869\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076931305 W= 0.251501 b= 0.801837\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076965168 W= 0.249976 b= 0.80155\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076942720 W= 0.250462 b= 0.801611\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076929525 W= 0.251135 b= 0.80173\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076958030 W= 0.2501 b= 0.801618\n",
      "迭代次数Epoch: 6100 下降值cost= 0.076990776 W= 0.249595 b= 0.801455\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076980092 W= 0.249741 b= 0.801496\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076942980 W= 0.251966 b= 0.802002\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076934047 W= 0.251649 b= 0.801944\n",
      "迭代次数Epoch: 6150 下降值cost= 0.077167138 W= 0.25441 b= 0.802356\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076932095 W= 0.250858 b= 0.801843\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076953508 W= 0.250185 b= 0.801682\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076932199 W= 0.250862 b= 0.801751\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076936081 W= 0.251748 b= 0.801894\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076931171 W= 0.250932 b= 0.801787\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076933876 W= 0.250773 b= 0.801714\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076938607 W= 0.251848 b= 0.801866\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076931305 W= 0.251501 b= 0.801834\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076965168 W= 0.249976 b= 0.801547\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076942727 W= 0.250462 b= 0.801608\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076929547 W= 0.251135 b= 0.801727\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076958045 W= 0.2501 b= 0.801615\n",
      "迭代次数Epoch: 6150 下降值cost= 0.076990761 W= 0.249595 b= 0.801452\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076980084 W= 0.249741 b= 0.801493\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076942988 W= 0.251966 b= 0.801999\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076934069 W= 0.25165 b= 0.801941\n",
      "迭代次数Epoch: 6200 下降值cost= 0.077167161 W= 0.254411 b= 0.802353\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076932110 W= 0.250858 b= 0.80184\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076953501 W= 0.250186 b= 0.801679\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076932207 W= 0.250863 b= 0.801748\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076936074 W= 0.251748 b= 0.801891\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076931149 W= 0.250933 b= 0.801784\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076933891 W= 0.250774 b= 0.801711\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076938599 W= 0.251848 b= 0.801863\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076931298 W= 0.251502 b= 0.801831\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076965161 W= 0.249977 b= 0.801544\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076942697 W= 0.250463 b= 0.801605\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076929532 W= 0.251136 b= 0.801724\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076958030 W= 0.250101 b= 0.801612\n",
      "迭代次数Epoch: 6200 下降值cost= 0.076990768 W= 0.249596 b= 0.801449\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076980099 W= 0.249742 b= 0.80149\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076942980 W= 0.251967 b= 0.801996\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076934047 W= 0.25165 b= 0.801938\n",
      "迭代次数Epoch: 6250 下降值cost= 0.077167161 W= 0.254411 b= 0.80235\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076932095 W= 0.250859 b= 0.801837\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076953515 W= 0.250186 b= 0.801676\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076932199 W= 0.250863 b= 0.801745\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076936081 W= 0.251749 b= 0.801888\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076931156 W= 0.250933 b= 0.801781\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076933876 W= 0.250774 b= 0.801708\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076938592 W= 0.251849 b= 0.80186\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076931313 W= 0.251502 b= 0.801828\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076965168 W= 0.249977 b= 0.801541\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076942712 W= 0.250463 b= 0.801602\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076929532 W= 0.251136 b= 0.801721\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076958030 W= 0.250101 b= 0.801609\n",
      "迭代次数Epoch: 6250 下降值cost= 0.076990761 W= 0.249596 b= 0.801446\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076980092 W= 0.249742 b= 0.801487\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076942980 W= 0.251967 b= 0.801993\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076934069 W= 0.251651 b= 0.801935\n",
      "迭代次数Epoch: 6300 下降值cost= 0.077167146 W= 0.254412 b= 0.802347\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076932110 W= 0.250859 b= 0.801834\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076953508 W= 0.250186 b= 0.801673\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076932199 W= 0.250864 b= 0.801742\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076936066 W= 0.251749 b= 0.801885\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076931171 W= 0.250933 b= 0.801778\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076933891 W= 0.250775 b= 0.801705\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076938592 W= 0.251849 b= 0.801857\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076931298 W= 0.251503 b= 0.801825\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076965153 W= 0.249977 b= 0.801538\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076942720 W= 0.250464 b= 0.801599\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076929539 W= 0.251136 b= 0.801718\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076958016 W= 0.250102 b= 0.801606\n",
      "迭代次数Epoch: 6300 下降值cost= 0.076990761 W= 0.249597 b= 0.801443\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076980099 W= 0.249743 b= 0.801484\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076942988 W= 0.251968 b= 0.80199\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076934047 W= 0.251651 b= 0.801933\n",
      "迭代次数Epoch: 6350 下降值cost= 0.077167183 W= 0.254412 b= 0.802344\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076932110 W= 0.25086 b= 0.801831\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076953508 W= 0.250187 b= 0.80167\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076932199 W= 0.250864 b= 0.801739\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076936074 W= 0.25175 b= 0.801882\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076931156 W= 0.250934 b= 0.801775\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076933883 W= 0.250775 b= 0.801702\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076938599 W= 0.25185 b= 0.801854\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076931305 W= 0.251503 b= 0.801822\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076965161 W= 0.249978 b= 0.801535\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076942690 W= 0.250464 b= 0.801596\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076929532 W= 0.251137 b= 0.801715\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076958030 W= 0.250102 b= 0.801603\n",
      "迭代次数Epoch: 6350 下降值cost= 0.076990739 W= 0.249597 b= 0.80144\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076980099 W= 0.249743 b= 0.801481\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076942980 W= 0.251968 b= 0.801987\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076934054 W= 0.251652 b= 0.80193\n",
      "迭代次数Epoch: 6400 下降值cost= 0.077167153 W= 0.254412 b= 0.802341\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076932110 W= 0.25086 b= 0.801828\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076953508 W= 0.250187 b= 0.801667\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076932192 W= 0.250865 b= 0.801736\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076936066 W= 0.25175 b= 0.801879\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076931164 W= 0.250934 b= 0.801772\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076933891 W= 0.250776 b= 0.801699\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076938592 W= 0.25185 b= 0.801851\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076931298 W= 0.251503 b= 0.801819\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076965161 W= 0.249978 b= 0.801532\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076942720 W= 0.250465 b= 0.801593\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076929532 W= 0.251137 b= 0.801712\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076958023 W= 0.250103 b= 0.8016\n",
      "迭代次数Epoch: 6400 下降值cost= 0.076990761 W= 0.249598 b= 0.801437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 6450 下降值cost= 0.076980084 W= 0.249743 b= 0.801478\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076942980 W= 0.251968 b= 0.801984\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076934069 W= 0.251652 b= 0.801927\n",
      "迭代次数Epoch: 6450 下降值cost= 0.077167153 W= 0.254413 b= 0.802338\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076932095 W= 0.25086 b= 0.801825\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076953508 W= 0.250188 b= 0.801664\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076932222 W= 0.250865 b= 0.801733\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076936066 W= 0.25175 b= 0.801876\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076931156 W= 0.250935 b= 0.801769\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076933876 W= 0.250776 b= 0.801696\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076938599 W= 0.25185 b= 0.801848\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076931305 W= 0.251504 b= 0.801816\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076965161 W= 0.249979 b= 0.801529\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076942697 W= 0.250465 b= 0.80159\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076929532 W= 0.251138 b= 0.801709\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076958045 W= 0.250103 b= 0.801597\n",
      "迭代次数Epoch: 6450 下降值cost= 0.076990753 W= 0.249598 b= 0.801434\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076980099 W= 0.249744 b= 0.801475\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076942980 W= 0.251969 b= 0.80198\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076934047 W= 0.251652 b= 0.801923\n",
      "迭代次数Epoch: 6500 下降值cost= 0.077167138 W= 0.254413 b= 0.802334\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076932102 W= 0.250861 b= 0.801822\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076953493 W= 0.250188 b= 0.80166\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076932207 W= 0.250866 b= 0.80173\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076936066 W= 0.251751 b= 0.801873\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076931156 W= 0.250935 b= 0.801765\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076933883 W= 0.250776 b= 0.801692\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076938592 W= 0.251851 b= 0.801845\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076931290 W= 0.251504 b= 0.801812\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076965153 W= 0.249979 b= 0.801525\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076942705 W= 0.250465 b= 0.801586\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076929525 W= 0.251138 b= 0.801705\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076958030 W= 0.250103 b= 0.801593\n",
      "迭代次数Epoch: 6500 下降值cost= 0.076990776 W= 0.249599 b= 0.801431\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076980092 W= 0.249745 b= 0.801469\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076942965 W= 0.25197 b= 0.801974\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076934040 W= 0.251653 b= 0.801917\n",
      "迭代次数Epoch: 6550 下降值cost= 0.077167124 W= 0.254414 b= 0.802328\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076932095 W= 0.250862 b= 0.801816\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076953501 W= 0.250189 b= 0.801654\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076932199 W= 0.250866 b= 0.801724\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076936059 W= 0.251751 b= 0.801867\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076931149 W= 0.250936 b= 0.801759\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076933883 W= 0.250777 b= 0.801686\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076938570 W= 0.251851 b= 0.801839\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076931283 W= 0.251505 b= 0.801807\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076965176 W= 0.24998 b= 0.801519\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076942727 W= 0.250466 b= 0.80158\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076929532 W= 0.251139 b= 0.801699\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076958038 W= 0.250104 b= 0.801588\n",
      "迭代次数Epoch: 6550 下降值cost= 0.076990768 W= 0.249599 b= 0.801425\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076980107 W= 0.249745 b= 0.801463\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076942965 W= 0.25197 b= 0.801969\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076934054 W= 0.251654 b= 0.801911\n",
      "迭代次数Epoch: 6600 下降值cost= 0.077167116 W= 0.254415 b= 0.802322\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076932088 W= 0.250863 b= 0.80181\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076953508 W= 0.25019 b= 0.801648\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076932199 W= 0.250867 b= 0.801718\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076936074 W= 0.251752 b= 0.801861\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076931156 W= 0.250937 b= 0.801753\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076933861 W= 0.250778 b= 0.80168\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076938592 W= 0.251852 b= 0.801833\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076931305 W= 0.251506 b= 0.801801\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076965168 W= 0.249981 b= 0.801513\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076942712 W= 0.250467 b= 0.801574\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076929539 W= 0.25114 b= 0.801693\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076958023 W= 0.250105 b= 0.801582\n",
      "迭代次数Epoch: 6600 下降值cost= 0.076990761 W= 0.2496 b= 0.801419\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076980099 W= 0.249746 b= 0.801457\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076942973 W= 0.251971 b= 0.801963\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076934054 W= 0.251655 b= 0.801905\n",
      "迭代次数Epoch: 6650 下降值cost= 0.077167146 W= 0.254416 b= 0.802316\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076932088 W= 0.250864 b= 0.801804\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076953486 W= 0.250191 b= 0.801642\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076932192 W= 0.250868 b= 0.801712\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076936059 W= 0.251753 b= 0.801855\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076931141 W= 0.250938 b= 0.801747\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076933868 W= 0.250779 b= 0.801674\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076938577 W= 0.251853 b= 0.801827\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076931298 W= 0.251507 b= 0.801795\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076965146 W= 0.249982 b= 0.801507\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076942705 W= 0.250468 b= 0.801568\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076929517 W= 0.251141 b= 0.801687\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076958038 W= 0.250106 b= 0.801576\n",
      "迭代次数Epoch: 6650 下降值cost= 0.076990776 W= 0.249601 b= 0.801413\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076980092 W= 0.249747 b= 0.801451\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076942973 W= 0.251972 b= 0.801957\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076934047 W= 0.251656 b= 0.801899\n",
      "迭代次数Epoch: 6700 下降值cost= 0.077167161 W= 0.254417 b= 0.802311\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076932095 W= 0.250864 b= 0.801798\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076953478 W= 0.250192 b= 0.801637\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076932184 W= 0.250869 b= 0.801706\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076936066 W= 0.251754 b= 0.801849\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076931134 W= 0.250939 b= 0.801741\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076933883 W= 0.25078 b= 0.801668\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076938577 W= 0.251854 b= 0.801821\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076931298 W= 0.251508 b= 0.801789\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076965138 W= 0.249982 b= 0.801502\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076942690 W= 0.250469 b= 0.801562\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076929517 W= 0.251142 b= 0.801681\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076958023 W= 0.250107 b= 0.80157\n",
      "迭代次数Epoch: 6700 下降值cost= 0.076990761 W= 0.249602 b= 0.801407\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076980084 W= 0.249748 b= 0.801445\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076942950 W= 0.251973 b= 0.801951\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076934047 W= 0.251657 b= 0.801893\n",
      "迭代次数Epoch: 6750 下降值cost= 0.077167138 W= 0.254418 b= 0.802305\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076932080 W= 0.250865 b= 0.801792\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076953478 W= 0.250193 b= 0.801631\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076932184 W= 0.25087 b= 0.8017\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076936059 W= 0.251755 b= 0.801843\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076931156 W= 0.250939 b= 0.801736\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076933861 W= 0.250781 b= 0.801662\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076938577 W= 0.251855 b= 0.801815\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076931298 W= 0.251509 b= 0.801783\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076965168 W= 0.249983 b= 0.801496\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076942705 W= 0.25047 b= 0.801556\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076929525 W= 0.251142 b= 0.801675\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076958016 W= 0.250108 b= 0.801564\n",
      "迭代次数Epoch: 6750 下降值cost= 0.076990746 W= 0.249603 b= 0.801401\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076980092 W= 0.249749 b= 0.801439\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076942973 W= 0.251974 b= 0.801945\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076934040 W= 0.251657 b= 0.801887\n",
      "迭代次数Epoch: 6800 下降值cost= 0.077167138 W= 0.254418 b= 0.802299\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076932095 W= 0.250866 b= 0.801786\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076953493 W= 0.250193 b= 0.801625\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076932199 W= 0.250871 b= 0.801694\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076936051 W= 0.251756 b= 0.801837\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076931149 W= 0.25094 b= 0.80173\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076933846 W= 0.250782 b= 0.801656\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076938570 W= 0.251856 b= 0.801809\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076931290 W= 0.251509 b= 0.801777\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076965146 W= 0.249984 b= 0.80149\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076942720 W= 0.25047 b= 0.80155\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076929532 W= 0.251143 b= 0.801669\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076958023 W= 0.250108 b= 0.801558\n",
      "迭代次数Epoch: 6800 下降值cost= 0.076990753 W= 0.249603 b= 0.801395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 6850 下降值cost= 0.076980084 W= 0.249749 b= 0.801435\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076942965 W= 0.251974 b= 0.801941\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076934054 W= 0.251658 b= 0.801884\n",
      "迭代次数Epoch: 6850 下降值cost= 0.077167124 W= 0.254419 b= 0.802295\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076932088 W= 0.250867 b= 0.801782\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076953478 W= 0.250194 b= 0.801621\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076932192 W= 0.250871 b= 0.80169\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076936059 W= 0.251756 b= 0.801834\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076931126 W= 0.250941 b= 0.801726\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076933868 W= 0.250782 b= 0.801653\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076938570 W= 0.251856 b= 0.801805\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076931290 W= 0.25151 b= 0.801773\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076965153 W= 0.249985 b= 0.801486\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076942705 W= 0.250471 b= 0.801547\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076929539 W= 0.251144 b= 0.801666\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076958030 W= 0.250109 b= 0.801554\n",
      "迭代次数Epoch: 6850 下降值cost= 0.076990783 W= 0.249604 b= 0.801391\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076980107 W= 0.24975 b= 0.801432\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076942965 W= 0.251975 b= 0.801938\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076934040 W= 0.251658 b= 0.801881\n",
      "迭代次数Epoch: 6900 下降值cost= 0.077167116 W= 0.254419 b= 0.802292\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076932095 W= 0.250867 b= 0.80178\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076953478 W= 0.250194 b= 0.801618\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076932184 W= 0.250871 b= 0.801687\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076936051 W= 0.251757 b= 0.801831\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076931141 W= 0.250941 b= 0.801723\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076933861 W= 0.250782 b= 0.80165\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076938570 W= 0.251857 b= 0.801802\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076931283 W= 0.25151 b= 0.80177\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076965153 W= 0.249985 b= 0.801483\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076942720 W= 0.250471 b= 0.801544\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076929517 W= 0.251144 b= 0.801663\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076958023 W= 0.250109 b= 0.801551\n",
      "迭代次数Epoch: 6900 下降值cost= 0.076990761 W= 0.249604 b= 0.801388\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076980092 W= 0.24975 b= 0.80143\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076942950 W= 0.251975 b= 0.801935\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076934040 W= 0.251659 b= 0.801878\n",
      "迭代次数Epoch: 6950 下降值cost= 0.077167138 W= 0.25442 b= 0.802289\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076932088 W= 0.250868 b= 0.801777\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076953471 W= 0.250195 b= 0.801615\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076932177 W= 0.250872 b= 0.801684\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076936059 W= 0.251757 b= 0.801828\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076931141 W= 0.250942 b= 0.80172\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076933868 W= 0.250783 b= 0.801647\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076938584 W= 0.251857 b= 0.801799\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076931283 W= 0.251511 b= 0.801767\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076965153 W= 0.249985 b= 0.80148\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076942697 W= 0.250472 b= 0.801541\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076929525 W= 0.251145 b= 0.80166\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076958023 W= 0.25011 b= 0.801548\n",
      "迭代次数Epoch: 6950 下降值cost= 0.076990753 W= 0.249605 b= 0.801385\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076980062 W= 0.249751 b= 0.801427\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076942973 W= 0.251976 b= 0.801932\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076934040 W= 0.251659 b= 0.801875\n",
      "迭代次数Epoch: 7000 下降值cost= 0.077167146 W= 0.25442 b= 0.802286\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076932065 W= 0.250868 b= 0.801774\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076953486 W= 0.250195 b= 0.801612\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076932169 W= 0.250872 b= 0.801681\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076936066 W= 0.251758 b= 0.801825\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076931134 W= 0.250942 b= 0.801717\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076933861 W= 0.250783 b= 0.801644\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076938570 W= 0.251858 b= 0.801796\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076931305 W= 0.251511 b= 0.801764\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076965153 W= 0.249986 b= 0.801477\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076942690 W= 0.250472 b= 0.801538\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076929510 W= 0.251145 b= 0.801657\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076958023 W= 0.25011 b= 0.801545\n",
      "迭代次数Epoch: 7000 下降值cost= 0.076990731 W= 0.249605 b= 0.801382\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076980077 W= 0.249751 b= 0.801424\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076942958 W= 0.251976 b= 0.801929\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076934040 W= 0.25166 b= 0.801872\n",
      "迭代次数Epoch: 7050 下降值cost= 0.077167153 W= 0.254421 b= 0.802283\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076932080 W= 0.250868 b= 0.801771\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076953471 W= 0.250196 b= 0.801609\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076932169 W= 0.250873 b= 0.801678\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076936066 W= 0.251758 b= 0.801822\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076931126 W= 0.250943 b= 0.801714\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076933861 W= 0.250784 b= 0.801641\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076938584 W= 0.251858 b= 0.801793\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076931275 W= 0.251512 b= 0.801761\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076965153 W= 0.249986 b= 0.801474\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076942690 W= 0.250473 b= 0.801535\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076929510 W= 0.251145 b= 0.801654\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076958001 W= 0.250111 b= 0.801542\n",
      "迭代次数Epoch: 7050 下降值cost= 0.076990739 W= 0.249606 b= 0.801379\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076980069 W= 0.249752 b= 0.801421\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076942958 W= 0.251977 b= 0.801926\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076934040 W= 0.25166 b= 0.801869\n",
      "迭代次数Epoch: 7100 下降值cost= 0.077167138 W= 0.254421 b= 0.80228\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076932088 W= 0.250869 b= 0.801768\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076953471 W= 0.250196 b= 0.801606\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076932192 W= 0.250873 b= 0.801675\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076936066 W= 0.251758 b= 0.801819\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076931141 W= 0.250943 b= 0.801711\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076933846 W= 0.250784 b= 0.801638\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076938570 W= 0.251859 b= 0.80179\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076931275 W= 0.251512 b= 0.801758\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076965146 W= 0.249987 b= 0.801471\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076942712 W= 0.250473 b= 0.801532\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076929510 W= 0.251146 b= 0.801651\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076958008 W= 0.250111 b= 0.801539\n",
      "迭代次数Epoch: 7100 下降值cost= 0.076990761 W= 0.249606 b= 0.801376\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076980084 W= 0.249752 b= 0.801418\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076942958 W= 0.251977 b= 0.801923\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076934040 W= 0.251661 b= 0.801866\n",
      "迭代次数Epoch: 7150 下降值cost= 0.077167146 W= 0.254422 b= 0.802277\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076932065 W= 0.250869 b= 0.801765\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076953486 W= 0.250196 b= 0.801603\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076932184 W= 0.250874 b= 0.801672\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076936036 W= 0.251759 b= 0.801816\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076931149 W= 0.250943 b= 0.801708\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076933846 W= 0.250785 b= 0.801635\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076938577 W= 0.251859 b= 0.801787\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076931298 W= 0.251512 b= 0.801755\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076965153 W= 0.249987 b= 0.801468\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076942697 W= 0.250473 b= 0.801529\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076929517 W= 0.251146 b= 0.801648\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076958016 W= 0.250111 b= 0.801536\n",
      "迭代次数Epoch: 7150 下降值cost= 0.076990761 W= 0.249607 b= 0.801373\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076980062 W= 0.249753 b= 0.801415\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076942965 W= 0.251978 b= 0.80192\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076934047 W= 0.251661 b= 0.801863\n",
      "迭代次数Epoch: 7200 下降值cost= 0.077167153 W= 0.254422 b= 0.802274\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076932073 W= 0.25087 b= 0.801762\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076953471 W= 0.250197 b= 0.8016\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076932184 W= 0.250874 b= 0.801669\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076936044 W= 0.251759 b= 0.801813\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076931141 W= 0.250944 b= 0.801705\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076933831 W= 0.250785 b= 0.801632\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076938577 W= 0.251859 b= 0.801784\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076931290 W= 0.251513 b= 0.801752\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076965153 W= 0.249988 b= 0.801465\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076942697 W= 0.250474 b= 0.801526\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076929510 W= 0.251147 b= 0.801645\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076958001 W= 0.250112 b= 0.801533\n",
      "迭代次数Epoch: 7200 下降值cost= 0.076990739 W= 0.249607 b= 0.801371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 7250 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7250 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7250 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7300 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7300 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7350 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7350 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7400 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7400 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7450 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7450 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7500 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7500 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7550 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7550 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7600 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7600 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 7650 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7650 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7650 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7700 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7700 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7750 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7750 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7800 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7800 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7850 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7850 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7900 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7900 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 7950 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 7950 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8000 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8000 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 8050 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8050 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8050 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8100 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8100 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8150 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8150 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8200 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8200 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8250 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8250 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8300 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8300 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8350 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8350 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8400 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8400 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 8450 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8450 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8450 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8500 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8500 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8550 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8550 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8600 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8600 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8650 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8650 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8700 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8700 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8750 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8750 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8800 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8800 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 8850 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8850 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8850 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8900 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8900 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 8950 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 8950 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9000 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9000 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9050 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9050 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9100 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9100 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9150 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9150 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9200 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9200 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 9250 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9250 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9250 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9300 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9300 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9350 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9350 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9400 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9400 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9450 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9450 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9500 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9500 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9550 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9550 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9600 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9600 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数Epoch: 9650 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9650 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9650 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9700 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9700 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9750 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9750 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9800 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9800 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9850 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9850 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9900 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9900 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 9950 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 9950 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076980077 W= 0.249753 b= 0.801412\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076942958 W= 0.251978 b= 0.801917\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076934040 W= 0.251661 b= 0.80186\n",
      "迭代次数Epoch: 10000 下降值cost= 0.077167131 W= 0.254422 b= 0.802271\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076932073 W= 0.25087 b= 0.801759\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076953471 W= 0.250197 b= 0.801597\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076932184 W= 0.250875 b= 0.801666\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076936044 W= 0.25176 b= 0.80181\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076931141 W= 0.250944 b= 0.801702\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076933846 W= 0.250785 b= 0.801629\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076938570 W= 0.25186 b= 0.801781\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076931283 W= 0.251513 b= 0.801749\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076965153 W= 0.249988 b= 0.801462\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076942690 W= 0.250474 b= 0.801523\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076929510 W= 0.251147 b= 0.801642\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076958008 W= 0.250112 b= 0.80153\n",
      "迭代次数Epoch: 10000 下降值cost= 0.076990739 W= 0.249607 b= 0.801368\n",
      "Optimizer Finished!\n",
      "Training cost= 0.0769907 W= 0.249607 b= 0.801368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing... (Mean square loss Comparison)\n",
      "Testing cost= 0.0791087\n",
      "Absolute mean square loss difference: 0.00211795\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEGCAYAAACgt3iRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8effe4940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng =numpy.random\n",
    "\n",
    "#参数设定\n",
    "learning_rate=0.01\n",
    "training_epochs=10000\n",
    "display_step=50        #每隔50次迭代输出一次\n",
    "#训练数据\n",
    "train_X=numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                       7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y=numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                       2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples=train_X.shape[0]\n",
    "print(\"train_X：\",train_X)\n",
    "print(\"train_Y：\",train_Y)  \n",
    "\n",
    "#设置placeholder\n",
    "X=tf.placeholder(\"float\")\n",
    "Y=tf.placeholder(\"float\")\n",
    "\n",
    "#设置模型的权重和偏置,因为是不断更新的所以采用Variable定义\n",
    "W=tf.Variable(rng.randn(),name=\"weight\")\n",
    "b=tf.Variable(rng.randn(),name=\"bias\")\n",
    "\n",
    "#设置线性回归方程LiR：w*x+b\n",
    "pred=tf.add(tf.multiply(X,W),b)\n",
    "cost=tf.reduce_sum(tf.pow(pred-Y,2))/(2*n_samples)  #设置cost为均方差即reduce_sum函数\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) #梯度下降，minimize函数默认下自动修正w和b \n",
    "\n",
    "init=tf.global_variables_initializer() #在session运算时初始化所有变量\n",
    "#开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)                        #运行一下初始化的变量\n",
    "    for epoch in range(training_epochs):  #输入所有训练数据\n",
    "        for(x,y) in zip(train_X,train_Y):\n",
    "            sess.run(optimizer,feed_dict={X:x,Y:y})\n",
    "            \n",
    "            #打印出每次迭代的log日志，每隔50个打印一次\n",
    "            if (epoch+1) % display_step ==0:\n",
    "                c=sess.run(cost,feed_dict={X:train_X,Y:train_Y})\n",
    "                print(\"迭代次数Epoch:\",\"%04d\" % (epoch+1),\"下降值cost=\",\"{:.9f}\".format(c),\n",
    "                      \"W=\",sess.run(W),\"b=\",sess.run(b))\n",
    "    print(\"Optimizer Finished!\")\n",
    "    training_cost=sess.run(cost,feed_dict={X:train_X,Y:train_Y})\n",
    "    print(\"Training cost=\",training_cost,\"W=\",sess.run(W),\"b=\",sess.run(b))\n",
    "    #绘图\n",
    "    plt.rcParams['font.sans-serif']=['SimHei']\n",
    "    plt.subplot(121)\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data') \n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend() \n",
    "    plt.title(\"TF之LiR：Original data By Jason NIu\")\n",
    "    \n",
    "    \n",
    "    #测试样本\n",
    "    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1]) \n",
    "    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831,2.92, 3.24, 1.35, 1.03])\n",
    "    print(\"Testing... (Mean square loss Comparison)\") \n",
    "    testing_cost = sess.run(tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]), \n",
    "                            feed_dict={X:test_X,Y:test_Y}) # same function as cost above \n",
    "    print(\"Testing cost=\", testing_cost) \n",
    "    print(\"Absolute mean square loss difference:\", abs( training_cost - testing_cost)) \n",
    "    #绘图\n",
    "    plt.subplot(122)\n",
    "    plt.plot(test_X, test_Y, 'bo', label='Testing data') \n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend() \n",
    "    plt.title(\"TF之LiR：Testing data By Jason NIu\")\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
